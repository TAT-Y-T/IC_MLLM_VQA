{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eed44a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # 或你要用的 GPU 编号\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"  # 关闭 TF 日志\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"  # 禁用 TF 优化，避免影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a382b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from peft import get_peft_model, PrefixTuningConfig, TaskType\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49cd4aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 筛选后的样本数量: 4349\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "def build_filtered_dataset(dataset_name='derek-thomas/ScienceQA',\n",
    "                           split='train',\n",
    "                           keep_grades='1-6'):\n",
    "    \"\"\"\n",
    "    构建按年级和图像存在性过滤的数据集。\n",
    "\n",
    "    参数:\n",
    "        dataset_name (str): 数据集名称，例如 'derek-thomas/ScienceQA'。\n",
    "        split (str): 数据分割，例如 'train', 'test', 'validation'。\n",
    "        keep_grades (str or None): 筛选的年级段：\"1-6\"、\"7-12\" 或 None 表示不过滤。\n",
    "\n",
    "    返回:\n",
    "        List[Dict]: 筛选后的样本列表。\n",
    "    \"\"\"\n",
    "\n",
    "    def is_grade_allowed(grade_str):\n",
    "        if keep_grades is None:\n",
    "            return True\n",
    "        try:\n",
    "            grade_num = int(grade_str.replace(\"grade\", \"\"))\n",
    "            if keep_grades == \"1-6\":\n",
    "                return 1 <= grade_num <= 6\n",
    "            elif keep_grades == \"7-12\":\n",
    "                return 7 <= grade_num <= 12\n",
    "        except:\n",
    "            return False\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "    data = load_dataset(dataset_name, split=split)\n",
    "    dataset = []\n",
    "\n",
    "    for i, sample in enumerate(data):\n",
    "        try:\n",
    "            if sample.get('question') is None:\n",
    "                continue\n",
    "            \n",
    "            if sample.get(\"image\", None) is None:\n",
    "                continue\n",
    "\n",
    "            if not is_grade_allowed(sample.get(\"grade\", \"\")):\n",
    "                continue\n",
    "\n",
    "            solution = sample.get(\"solution\", \"\")\n",
    "            lecture = sample.get(\"lecture\", \"\")\n",
    "            solution_lecture = f\"{solution}\\n\\n{lecture}\".strip()\n",
    "            \n",
    "            image = sample[\"image\"].convert(\"RGB\")\n",
    "            \n",
    "\n",
    "            # image = np.array(image)\n",
    "            # image = torch.tensor(image).permute(2, 0, 1)  # shape: (C, H, W)\n",
    "            dataset.append({\n",
    "                \"image\": image, \n",
    "                \"question\": sample[\"question\"],\n",
    "                \"choices\": sample[\"choices\"],\n",
    "                \"hint\": sample[\"hint\"],\n",
    "                \"answer\": sample[\"answer\"],\n",
    "                \"solution_lecture\": solution_lecture,\n",
    "                'grade':sample[\"grade\"],\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"跳过第 {i} 个样本，错误：{e}\")\n",
    "            continue\n",
    "    return dataset\n",
    "\n",
    "dataset_train = build_filtered_dataset(split='train', keep_grades='1-6')\n",
    "print(f\"\\n✅ 筛选后的样本数量: {len(dataset_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e166d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 筛选后的样本数量: 1429\n"
     ]
    }
   ],
   "source": [
    "dataset_val = build_filtered_dataset(split='test', keep_grades='1-6')\n",
    "print(f\"\\n✅ 筛选后的样本数量: {len(dataset_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f98ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which of these states is farthest south?\n",
      "Choices: ['Nebraska', 'Minnesota', 'Idaho', 'New Hampshire']\n",
      "Hint: \n",
      "Grade: grade2\n",
      "Answer: 0\n",
      "Explanation: To find the answer, look at the compass rose. Look at which way the south arrow is pointing. Nebraska is farthest south.\n",
      "\n",
      "Maps have four cardinal directions, or main directions. Those directions are north, south, east, and west.\n",
      "A compass rose is a set of arrows that point to the cardinal directions. A compass rose usually shows only the first letter of each cardinal direction.\n",
      "The north arrow points to the North Pole. On most maps, north is at the top of the map.\n",
      "Image type: <class 'PIL.Image.Image'>\n"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    "\n",
    "sample_1 = choice(dataset_train)\n",
    "print(f\"Question: {sample_1['question']}\")\n",
    "print(f\"Choices: {sample_1['choices']}\")\n",
    "print(f\"Hint: {sample_1['hint']}\")\n",
    "print(f\"Grade: {sample_1['grade']}\")\n",
    "print(f\"Answer: {sample_1['answer']}\")\n",
    "print(f\"Explanation: {sample_1['solution_lecture']}\")\n",
    "print(f\"Image type: {type(sample_1['image'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a5efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "class QwenVLPrefixDataset(Dataset):\n",
    "    def __init__(self, data_list, processor, max_label_length=256, debug=False):\n",
    "        self.data_list = data_list\n",
    "        self.processor = processor\n",
    "        self.max_label_length = max_label_length\n",
    "        self.debug = debug\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data_list[idx]\n",
    "        return self.build_training_sample(sample)\n",
    "\n",
    "    def build_training_sample(self, sample):\n",
    "        # 1. 处理答案\n",
    "        if isinstance(sample[\"answer\"], int):\n",
    "            answer_index = sample[\"answer\"]\n",
    "        else:\n",
    "            answer_index = sample[\"choices\"].index(sample[\"answer\"])\n",
    "        answer_letter = chr(65 + answer_index)\n",
    "\n",
    "        # 2. 构建问题内容\n",
    "        question_text = f\"Question: {sample['question']}\\nChoices:\\n\"\n",
    "        for idx, choice in enumerate(sample[\"choices\"]):\n",
    "            question_text += f\"{chr(65 + idx)}. {choice}\\n\"\n",
    "        if sample.get(\"hint\"):\n",
    "            question_text += f\"\\nHint: {sample['hint']}\\n\"\n",
    "        question_text += (\n",
    "            \"\\nHere is a image:\\n\"\n",
    "            \"Please select the correct answer. Then, explain your reasoning in detail. \"\n",
    "            \"Make sure your explanation is at least three sentences long, \"\n",
    "            \"refers to specific data from the image, and shows your step-by-step logic.\"\n",
    "        )\n",
    "\n",
    "        # 3. 构造 chat + 图像\n",
    "        image = sample[\"image\"]\n",
    "        if not isinstance(image, Image.Image):\n",
    "            raise ValueError(\"image must be a PIL.Image.Image\")\n",
    "        image = image.convert(\"RGB\").resize((224, 224))\n",
    "\n",
    "        chat = [\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": question_text},\n",
    "                {\"type\": \"image\",\"image\": image}\n",
    "            ]}\n",
    "        ]\n",
    "        prompt = self.processor.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "        # 4. 编码图文输入（注意不要设置 truncation 或 max_length）\n",
    "        inputs = self.processor(\n",
    "            text=prompt,\n",
    "            images=image,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"longest\",   # ✅ 自动对齐\n",
    "            truncation=False     # ✅ 不截断任何 token\n",
    "        )\n",
    "\n",
    "        # 5. 编码标签\n",
    "        label_text = f\"Answer: {answer_letter}\\nExplanation: {sample['solution_lecture']}\"\n",
    "        tokenizer = self.processor.tokenizer\n",
    "        \n",
    "        input_len = inputs[\"input_ids\"].shape[1]\n",
    "        \n",
    "        label_ids = tokenizer(\n",
    "            label_text,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=input_len\n",
    "        )[\"input_ids\"]\n",
    "        label_ids[label_ids == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        # 6. 返回项（确保 input_ids 和 attention_mask 等长）\n",
    "        input_ids = inputs[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = inputs[\"attention_mask\"].squeeze(0)\n",
    "        if input_ids.shape != attention_mask.shape:\n",
    "            raise ValueError(f\"input_ids shape {input_ids.shape} ≠ attention_mask shape {attention_mask.shape}\")\n",
    "\n",
    "        result = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": label_ids.squeeze(0),\n",
    "            \"pixel_values\": inputs[\"pixel_values\"].squeeze(0),\n",
    "        }\n",
    "\n",
    "        if \"image_grid_thw\" in inputs:\n",
    "            result[\"image_grid_thw\"] = inputs[\"image_grid_thw\"].squeeze(0)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] input_ids: {input_ids.shape}\")\n",
    "            print(f\"[DEBUG] attention_mask: {attention_mask.shape}\")\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5519615c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 假设你已经有了 data_list，每个元素包含 image（路径或PIL对象）、question、choices、hint、answer、solution_lecture\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-3B-Instruct\")\n",
    "train_dataset = QwenVLPrefixDataset(dataset_train, processor, debug=False)\n",
    "val_dataset = QwenVLPrefixDataset(dataset_val, processor, debug=False)\n",
    "dataloader = DataLoader(dataset_train, batch_size=6, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8434da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def qwen_vl_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    可自动 pad 的 collate 函数，适配不同长度 input_ids / labels。\n",
    "    \"\"\"\n",
    "    def pad_tensor_list(tensor_list, pad_value=0):\n",
    "        return pad_sequence(tensor_list, batch_first=True, padding_value=pad_value)\n",
    "\n",
    "    input_ids = [item[\"input_ids\"] for item in batch]\n",
    "    attention_mask = [item[\"attention_mask\"] for item in batch]\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "    pixel_values = [item[\"pixel_values\"] for item in batch]  # 通常 shape 一致，可直接 stack\n",
    "    image_grid_thw = [item[\"image_grid_thw\"] for item in batch]  # 通常 shape 一致，可直接 stack\n",
    "\n",
    "    input_ids = pad_tensor_list(input_ids, pad_value=0)\n",
    "    attention_mask = pad_tensor_list(attention_mask, pad_value=0)\n",
    "    labels = pad_tensor_list(labels, pad_value=-100)  # 对 labels padding 用 -100 避免影响 loss\n",
    "    pixel_values = torch.stack(pixel_values)\n",
    "    image_grid_thw = torch.stack(image_grid_thw)\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        # \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels,\n",
    "        \"pixel_values\": pixel_values,\n",
    "        'image_grid_thw': image_grid_thw\n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79562971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== 第一个 batch 的第一个样本 ====\n",
      "input_ids shape: torch.Size([162])\n",
      "labels shape: torch.Size([162])\n",
      "pixel_values shape: torch.Size([256, 1176])\n",
      "image_grid_thw shape: torch.Size([3])\n",
      "\n",
      "--- 解码后的 input_ids ---\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Question: What is the name of the colony shown?\n",
      "Choices:\n",
      "A. Maryland\n",
      "B. New Hampshire\n",
      "C. Rhode Island\n",
      "D. Vermont\n",
      "\n",
      "Here is a image:\n",
      "Please select the correct answer. Then, explain your reasoning in detail. Make sure your explanation is at least three sentences long, refers to specific data from the image, and shows your step-by-step logic.\n",
      "assistant\n",
      "\n",
      "\n",
      "--- 解码后的 labels ---\n",
      "Answer: B\n",
      "Explanation: The colony is New Hampshire.\n",
      "During the colonial era, New Hampshire and New York both claimed the territory that would later become the state of Vermont. Vermont was never its own colony.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 正确使用 collate_fn\n",
    "\n",
    "dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=qwen_vl_collate_fn)\n",
    "\n",
    "# 获取第一个 batch\n",
    "first_batch = next(iter(dataloader))\n",
    "\n",
    "# 查看第一个样本的结构\n",
    "print(\"==== 第一个 batch 的第一个样本 ====\")\n",
    "print(f\"input_ids shape: {first_batch['input_ids'][0].shape}\")\n",
    "# print(f\"attention_mask shape: {first_batch['attention_mask'][0].shape}\")\n",
    "print(f\"labels shape: {first_batch['labels'][0].shape}\")\n",
    "print(f\"pixel_values shape: {first_batch['pixel_values'][0].shape}\")\n",
    "print(f\"image_grid_thw shape: {first_batch['image_grid_thw'][0].shape}\")\n",
    "\n",
    "# 可选：查看文本内容（需要 tokenizer）\n",
    "tokenizer = processor.tokenizer\n",
    "decoded_input = tokenizer.decode(first_batch['input_ids'][0], skip_special_tokens=True)\n",
    "decoded_label = tokenizer.decode(\n",
    "    [id for id in first_batch['labels'][0].tolist() if id != -100],\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(\"\\n--- 解码后的 input_ids ---\")\n",
    "print(decoded_input)\n",
    "\n",
    "print(\"\\n--- 解码后的 labels ---\")\n",
    "print(decoded_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fbbc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-3B-Instruct\", device_map=\"auto\", torch_dtype=torch.bfloat16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c7ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = PrefixTuningConfig(\n",
    "    task_type='CAUSAL_LM',\n",
    "    inference_mode=False,\n",
    "    num_virtual_tokens=12,\n",
    "    prefix_projection=True\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "796f8352",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):  # 屏蔽 num_items_in_batch\n",
    "        if \"num_items_in_batch\" in kwargs:\n",
    "            kwargs.pop(\"num_items_in_batch\")\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14060ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge import Rouge\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "\n",
    "def parse_output(output):\n",
    "    output = output.strip()\n",
    "\n",
    "    # case 1: \"Answer: A Explanation: xxx\"\n",
    "    match = re.search(r\"Answer[:：]?\\s*([A-D])\\b.*?Explanation[:：]?\\s*(.+)\", output, re.DOTALL)\n",
    "    if match:\n",
    "        answer = ord(match.group(1)) - 65\n",
    "        explanation = match.group(2).strip()\n",
    "        return answer, explanation\n",
    "\n",
    "    # case 2: \"A Explanation: xxx\"\n",
    "    match = re.match(r\"\\b([A-D])\\s*Explanation[:：]?\\s*(.+)\", output, re.DOTALL)\n",
    "    if match:\n",
    "        answer = ord(match.group(1)) - 65\n",
    "        explanation = match.group(2).strip()\n",
    "        return answer, explanation\n",
    "\n",
    "    # case 3: \"A. xxx\" or \"B: xxx\"\n",
    "    match = re.match(r\"\\b([A-D])[\\.:]\\s*(.+)\", output, re.DOTALL)\n",
    "    if match:\n",
    "        answer = ord(match.group(1)) - 65\n",
    "        explanation = match.group(2).strip()\n",
    "        return answer, explanation\n",
    "\n",
    "    # case 4: only one letter like \"C\"\n",
    "    match = re.match(r\"^\\s*([A-D])\\s*$\", output)\n",
    "    if match:\n",
    "        answer = ord(match.group(1)) - 65\n",
    "        return answer, \"\"\n",
    "\n",
    "    # fallback: try to find first capital letter A-D (unsafe)\n",
    "    match = re.search(r\"\\b([A-D])\\b\", output)\n",
    "    if match:\n",
    "        answer = ord(match.group(1)) - 65\n",
    "        explanation = output[match.end():].strip()\n",
    "        return answer, explanation\n",
    "\n",
    "    return -1, \"\"\n",
    "\n",
    "def keyword_overlap(pred, ref):\n",
    "    pred_keywords = set(pred.lower().split())\n",
    "    ref_keywords = set(ref.lower().split())\n",
    "    if not ref_keywords:\n",
    "        return 0.0\n",
    "    return len(pred_keywords & ref_keywords) / len(ref_keywords)\n",
    "\n",
    "MAX_LEN = 1024\n",
    "smoothie = SmoothingFunction().method4\n",
    "\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# ==== 全局设置 ====\n",
    "MAX_LEN = 512\n",
    "smoothie = SmoothingFunction().method4\n",
    "global_rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "\n",
    "# ==== Keyword Overlap ====\n",
    "def keyword_overlap(pred, ref):\n",
    "    pred_keywords = set(pred.lower().split())\n",
    "    ref_keywords = set(ref.lower().split())\n",
    "    if not ref_keywords:\n",
    "        return 0.0\n",
    "    return len(pred_keywords & ref_keywords) / len(ref_keywords)\n",
    "\n",
    "# ==== Metric 函数 ====\n",
    "def compute_metrics(eval_preds, tokenizer):\n",
    "    predictions = eval_preds.predictions\n",
    "    label_ids = eval_preds.label_ids\n",
    "    inputs = eval_preds.inputs if hasattr(eval_preds, \"inputs\") else None  # 如果你想一起打印输入\n",
    "\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "    if predictions.ndim == 3:\n",
    "        predictions = predictions.argmax(-1)\n",
    "\n",
    "    decoded_preds = []\n",
    "    decoded_labels = []\n",
    "\n",
    "    print(\"\\n================= Sample Predictions =================\")\n",
    "    for i, (pred_ids, label) in enumerate(zip(predictions, label_ids)):\n",
    "        try:\n",
    "            label = [id for id in label if id != -100]\n",
    "            if hasattr(pred_ids, \"tolist\"):\n",
    "                pred_ids = pred_ids.tolist()\n",
    "\n",
    "            decoded_pred = tokenizer.decode(pred_ids, skip_special_tokens=True)\n",
    "            decoded_label = tokenizer.decode(label, skip_special_tokens=True)\n",
    "\n",
    "            decoded_pred = decoded_pred.encode(\"utf-8\", errors=\"ignore\").decode(\"utf-8\", errors=\"ignore\")[:MAX_LEN].strip()\n",
    "            decoded_label = decoded_label.encode(\"utf-8\", errors=\"ignore\").decode(\"utf-8\", errors=\"ignore\")[:MAX_LEN].strip()\n",
    "\n",
    "            if not decoded_pred or not decoded_label:\n",
    "                continue\n",
    "\n",
    "            decoded_preds.append(decoded_pred)\n",
    "            decoded_labels.append(decoded_label)\n",
    "\n",
    "            # 👉 打印输入输出对（可选加输入）\n",
    "            print(f\"[{i}]\")\n",
    "            if inputs is not None and \"input_ids\" in inputs:\n",
    "                input_ids = inputs[\"input_ids\"][i].tolist()\n",
    "                decoded_input = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "                print(f\"🟡 Input: {decoded_input}\")\n",
    "            print(f\"🔵 Label: {decoded_label}\")\n",
    "            print(f\"🟢 Pred : {decoded_pred}\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[❌ Decode error at sample {i}] {e}\")\n",
    "            continue\n",
    "\n",
    "    # === Metric ===\n",
    "    bleu1_scores = []\n",
    "    bleu4_scores = []\n",
    "    rouge_l_scores = []\n",
    "    keyword_overlaps = []\n",
    "    choice_correct = []\n",
    "\n",
    "    for i, (pred, label) in enumerate(zip(decoded_preds, decoded_labels)):\n",
    "        try:\n",
    "            reference = label.split()\n",
    "            candidate = pred.split()\n",
    "\n",
    "            if not reference or not candidate:\n",
    "                continue\n",
    "\n",
    "            bleu1 = sentence_bleu([reference], candidate, weights=(1, 0, 0, 0), smoothing_function=smoothie)\n",
    "            bleu4 = sentence_bleu([reference], candidate, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie)\n",
    "            rouge_l = global_rouge.score(label, pred)[\"rougeL\"].fmeasure\n",
    "            keyword_acc = keyword_overlap(pred, label)\n",
    "\n",
    "            pred_choice, _ = parse_output(pred)\n",
    "            label_choice, _ = parse_output(label)\n",
    "            correct = int(pred_choice == label_choice and pred_choice != -1)\n",
    "\n",
    "            bleu1_scores.append(bleu1)\n",
    "            bleu4_scores.append(bleu4)\n",
    "            rouge_l_scores.append(rouge_l)\n",
    "            keyword_overlaps.append(keyword_acc)\n",
    "            choice_correct.append(correct)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[❌ Metric error at sample {i}] {e}\")\n",
    "            continue\n",
    "\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return {\n",
    "        \"BLEU-1\": np.mean(bleu1_scores) if bleu1_scores else 0.0,\n",
    "        \"BLEU-4\": np.mean(bleu4_scores) if bleu4_scores else 0.0,\n",
    "        \"ROUGE-L\": np.mean(rouge_l_scores) if rouge_l_scores else 0.0,\n",
    "        \"KeywordOverlap\": np.mean(keyword_overlaps) if keyword_overlaps else 0.0,\n",
    "        \"ChoiceAccuracy\": np.mean(choice_correct) if choice_correct else 0.0,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3586bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-3B-Instruct\")\n",
    "small_train_dataset=dataset_train\n",
    "small_val_dataset=dataset_val\n",
    "train_dataset = QwenVLPrefixDataset(small_train_dataset, processor, debug=False)\n",
    "val_dataset = QwenVLPrefixDataset(small_val_dataset, processor, debug=False)    \n",
    "# dataloader = DataLoader(train_dataset, batch_size=6, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "804580d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "[codecarbon ERROR @ 18:14:06] Error: Another instance of codecarbon is probably running as we find `/tmp/.codecarbon.lock`. Turn off the other instance to be able to run this one or use `allow_multiple_runs` or delete the file. Exiting.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qwen2.5vl-prefix2.03B\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=1, \n",
    "    dataloader_num_workers=0,\n",
    "    eval_accumulation_steps=1,\n",
    "    learning_rate=5e-4,\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    bf16=True,  # 如果使用的是支持 bfloat16 的 GPU，可改为 bf16=True\n",
    "    gradient_accumulation_steps=4,\n",
    "    do_eval=True,\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=qwen_vl_collate_fn,\n",
    "    compute_metrics=lambda p: compute_metrics(p, tokenizer=processor.tokenizer)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21c2d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef8c9fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4aacb19a36495f8f17ed5ff7a84401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForVision2Seq\n",
    "from peft import PeftModel\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 第一步：加载 base 模型（视觉语言模型）\n",
    "base_model =  AutoModelForVision2Seq.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-3B-Instruct\",\n",
    "    device_map={\"\": device},\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    ")\n",
    "\n",
    "# 第二步：加载 Prefix Tuning 权重\n",
    "prefix_path = \"./qwen2.5vl-prefix2.03B/checkpoint-1360\"  # 比如 checkpoint-1360\n",
    "model = PeftModel.from_pretrained(base_model, prefix_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "430fbddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc6652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e5e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01923cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_step_by_step(model, dataset, tokenizer, collate_fn, batch_size=1, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "\n",
    "    bleu1_scores = []\n",
    "    bleu4_scores = []\n",
    "    rouge_l_scores = []\n",
    "    keyword_overlaps = []\n",
    "    choice_correct = []\n",
    "\n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "        # Move to device\n",
    "        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        # 获取 logits → token ids\n",
    "        if hasattr(outputs, \"logits\"):\n",
    "            pred_ids = outputs.logits.argmax(-1).detach().cpu().tolist()\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        label_ids = batch[\"labels\"].detach().cpu().tolist()\n",
    "\n",
    "        # decode\n",
    "        for j, (pred, label) in enumerate(zip(pred_ids, label_ids)):\n",
    "            pred_text = tokenizer.decode(pred, skip_special_tokens=True)\n",
    "            label_text = tokenizer.decode([id for id in label if id != -100], skip_special_tokens=True)\n",
    "\n",
    "            ref = label_text.split()\n",
    "            cand = pred_text.split()\n",
    "            if not ref or not cand:\n",
    "                continue\n",
    "\n",
    "            # 计算各项指标\n",
    "            bleu1 = sentence_bleu([ref], cand, weights=(1, 0, 0, 0), smoothing_function=smoothie)\n",
    "            bleu4 = sentence_bleu([ref], cand, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie)\n",
    "            rouge_l = global_rouge.score(label_text, pred_text)[\"rougeL\"].fmeasure\n",
    "            keyword_acc = keyword_overlap(pred_text, label_text)\n",
    "\n",
    "            pred_choice, _ = parse_output(pred_text)\n",
    "            label_choice, _ = parse_output(label_text)\n",
    "            correct = int(pred_choice == label_choice and pred_choice != -1)\n",
    "\n",
    "            # 记录\n",
    "            bleu1_scores.append(bleu1)\n",
    "            bleu4_scores.append(bleu4)\n",
    "            rouge_l_scores.append(rouge_l)\n",
    "            keyword_overlaps.append(keyword_acc)\n",
    "            choice_correct.append(correct)\n",
    "\n",
    "            # 每条输出一条，清空上一条\n",
    "            clear_output(wait=True)\n",
    "            print(f\"\\n[Sample {i * batch_size + j}]\")\n",
    "            print(f\"🔹BLEU-1: {bleu1:.4f}  BLEU-4: {bleu4:.4f}\")\n",
    "            print(f\"🔹ROUGE-L: {rouge_l:.4f}  KeywordOverlap: {keyword_acc:.4f}\")\n",
    "            print(f\"🔹ChoiceAccuracy: {correct}\")\n",
    "            print(f\"🔸Reference: {label_text}\")\n",
    "            print(f\"🔸Prediction: {pred_text}\")\n",
    "\n",
    "    # 返回平均分\n",
    "    return {\n",
    "        \"BLEU-1\": np.mean(bleu1_scores) if bleu1_scores else 0.0,\n",
    "        \"BLEU-4\": np.mean(bleu4_scores) if bleu4_scores else 0.0,\n",
    "        \"ROUGE-L\": np.mean(rouge_l_scores) if rouge_l_scores else 0.0,\n",
    "        \"KeywordOverlap\": np.mean(keyword_overlaps) if keyword_overlaps else 0.0,\n",
    "        \"ChoiceAccuracy\": np.mean(choice_correct) if choice_correct else 0.0,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4e7e0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1429/1429 [02:35<00:00,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample 1428]\n",
      "🔹BLEU-1: 0.1371  BLEU-4: 0.0169\n",
      "🔹ROUGE-L: 0.1857  KeywordOverlap: 0.3000\n",
      "🔹ChoiceAccuracy: 0\n",
      "🔸Reference: Answer: A\n",
      "Explanation: The bulldozer pushes the loose dirt. The direction of the push is away from the bulldozer.\n",
      "\n",
      "A force is a push or a pull that one object applies to another. Every force has a direction.\n",
      "The direction of a push is away from the object that is pushing.\n",
      "The direction of a pull is toward the object that is pulling.\n",
      "🔸Prediction: : B\n",
      "Explanation: Look is the capital of the... rose. it.. is. the. a force push force direction direction a direction direction direction direction direction. a a direction push direction direction of a a a push direction. direction direction a a of a of a a direction a a a a a a a a a a object. a of a object. a of the direction a a a direction a a is a a a a a a a the a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a of a a a a a a a a a a a a a a a a a a a a of a a a a a a a a a a a a a a a a a a a a a a a force force a a force force force force a force a direction a The force direction a a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU-1': 0.22413028480130578,\n",
       " 'BLEU-4': 0.07225036086702381,\n",
       " 'ROUGE-L': 0.2542470650297796,\n",
       " 'KeywordOverlap': 0.3902395612075573,\n",
       " 'ChoiceAccuracy': 0.3547935619314206}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_step_by_step(model, val_dataset, processor.tokenizer, qwen_vl_collate_fn, batch_size=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
