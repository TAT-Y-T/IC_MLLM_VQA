{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eed44a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # æˆ–ä½ è¦ç”¨çš„ GPU ç¼–å·\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"  # å…³é—­ TF æ—¥å¿—\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"  # ç¦ç”¨ TF ä¼˜åŒ–ï¼Œé¿å…å½±å“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a382b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from peft import get_peft_model, PrefixTuningConfig, TaskType\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49cd4aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ç­›é€‰åçš„æ ·æœ¬æ•°é‡: 4349\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "def build_filtered_dataset(dataset_name='derek-thomas/ScienceQA',\n",
    "                           split='train',\n",
    "                           keep_grades='1-6'):\n",
    "    \"\"\"\n",
    "    æ„å»ºæŒ‰å¹´çº§å’Œå›¾åƒå­˜åœ¨æ€§è¿‡æ»¤çš„æ•°æ®é›†ã€‚\n",
    "\n",
    "    å‚æ•°:\n",
    "        dataset_name (str): æ•°æ®é›†åç§°ï¼Œä¾‹å¦‚ 'derek-thomas/ScienceQA'ã€‚\n",
    "        split (str): æ•°æ®åˆ†å‰²ï¼Œä¾‹å¦‚ 'train', 'test', 'validation'ã€‚\n",
    "        keep_grades (str or None): ç­›é€‰çš„å¹´çº§æ®µï¼š\"1-6\"ã€\"7-12\" æˆ– None è¡¨ç¤ºä¸è¿‡æ»¤ã€‚\n",
    "\n",
    "    è¿”å›:\n",
    "        List[Dict]: ç­›é€‰åçš„æ ·æœ¬åˆ—è¡¨ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    def is_grade_allowed(grade_str):\n",
    "        if keep_grades is None:\n",
    "            return True\n",
    "        try:\n",
    "            grade_num = int(grade_str.replace(\"grade\", \"\"))\n",
    "            if keep_grades == \"1-6\":\n",
    "                return 1 <= grade_num <= 6\n",
    "            elif keep_grades == \"7-12\":\n",
    "                return 7 <= grade_num <= 12\n",
    "        except:\n",
    "            return False\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "    data = load_dataset(dataset_name, split=split)\n",
    "    dataset = []\n",
    "\n",
    "    for i, sample in enumerate(data):\n",
    "        try:\n",
    "            if sample.get('question') is None:\n",
    "                continue\n",
    "            \n",
    "            if sample.get(\"image\", None) is None:\n",
    "                continue\n",
    "\n",
    "            if not is_grade_allowed(sample.get(\"grade\", \"\")):\n",
    "                continue\n",
    "\n",
    "            solution = sample.get(\"solution\", \"\")\n",
    "            lecture = sample.get(\"lecture\", \"\")\n",
    "            solution_lecture = f\"{solution}\\n\\n{lecture}\".strip()\n",
    "            \n",
    "            image = sample[\"image\"].convert(\"RGB\")\n",
    "            \n",
    "\n",
    "            # image = np.array(image)\n",
    "            # image = torch.tensor(image).permute(2, 0, 1)  # shape: (C, H, W)\n",
    "            dataset.append({\n",
    "                \"image\": image, \n",
    "                \"question\": sample[\"question\"],\n",
    "                \"choices\": sample[\"choices\"],\n",
    "                \"hint\": sample[\"hint\"],\n",
    "                \"answer\": sample[\"answer\"],\n",
    "                \"solution_lecture\": solution_lecture,\n",
    "                'grade':sample[\"grade\"],\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"è·³è¿‡ç¬¬ {i} ä¸ªæ ·æœ¬ï¼Œé”™è¯¯ï¼š{e}\")\n",
    "            continue\n",
    "    return dataset\n",
    "\n",
    "dataset_train = build_filtered_dataset(split='train', keep_grades='1-6')\n",
    "print(f\"\\nâœ… ç­›é€‰åçš„æ ·æœ¬æ•°é‡: {len(dataset_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e166d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ç­›é€‰åçš„æ ·æœ¬æ•°é‡: 1429\n"
     ]
    }
   ],
   "source": [
    "dataset_val = build_filtered_dataset(split='test', keep_grades='1-6')\n",
    "print(f\"\\nâœ… ç­›é€‰åçš„æ ·æœ¬æ•°é‡: {len(dataset_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f98ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which of these states is farthest south?\n",
      "Choices: ['Nebraska', 'Minnesota', 'Idaho', 'New Hampshire']\n",
      "Hint: \n",
      "Grade: grade2\n",
      "Answer: 0\n",
      "Explanation: To find the answer, look at the compass rose. Look at which way the south arrow is pointing. Nebraska is farthest south.\n",
      "\n",
      "Maps have four cardinal directions, or main directions. Those directions are north, south, east, and west.\n",
      "A compass rose is a set of arrows that point to the cardinal directions. A compass rose usually shows only the first letter of each cardinal direction.\n",
      "The north arrow points to the North Pole. On most maps, north is at the top of the map.\n",
      "Image type: <class 'PIL.Image.Image'>\n"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    "\n",
    "sample_1 = choice(dataset_train)\n",
    "print(f\"Question: {sample_1['question']}\")\n",
    "print(f\"Choices: {sample_1['choices']}\")\n",
    "print(f\"Hint: {sample_1['hint']}\")\n",
    "print(f\"Grade: {sample_1['grade']}\")\n",
    "print(f\"Answer: {sample_1['answer']}\")\n",
    "print(f\"Explanation: {sample_1['solution_lecture']}\")\n",
    "print(f\"Image type: {type(sample_1['image'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a5efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "class QwenVLPrefixDataset(Dataset):\n",
    "    def __init__(self, data_list, processor, max_label_length=256, debug=False):\n",
    "        self.data_list = data_list\n",
    "        self.processor = processor\n",
    "        self.max_label_length = max_label_length\n",
    "        self.debug = debug\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data_list[idx]\n",
    "        return self.build_training_sample(sample)\n",
    "\n",
    "    def build_training_sample(self, sample):\n",
    "        # 1. å¤„ç†ç­”æ¡ˆ\n",
    "        if isinstance(sample[\"answer\"], int):\n",
    "            answer_index = sample[\"answer\"]\n",
    "        else:\n",
    "            answer_index = sample[\"choices\"].index(sample[\"answer\"])\n",
    "        answer_letter = chr(65 + answer_index)\n",
    "\n",
    "        # 2. æ„å»ºé—®é¢˜å†…å®¹\n",
    "        question_text = f\"Question: {sample['question']}\\nChoices:\\n\"\n",
    "        for idx, choice in enumerate(sample[\"choices\"]):\n",
    "            question_text += f\"{chr(65 + idx)}. {choice}\\n\"\n",
    "        if sample.get(\"hint\"):\n",
    "            question_text += f\"\\nHint: {sample['hint']}\\n\"\n",
    "        question_text += (\n",
    "            \"\\nHere is a image:\\n\"\n",
    "            \"Please select the correct answer. Then, explain your reasoning in detail. \"\n",
    "            \"Make sure your explanation is at least three sentences long, \"\n",
    "            \"refers to specific data from the image, and shows your step-by-step logic.\"\n",
    "        )\n",
    "\n",
    "        # 3. æ„é€  chat + å›¾åƒ\n",
    "        image = sample[\"image\"]\n",
    "        if not isinstance(image, Image.Image):\n",
    "            raise ValueError(\"image must be a PIL.Image.Image\")\n",
    "        image = image.convert(\"RGB\").resize((224, 224))\n",
    "\n",
    "        chat = [\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": question_text},\n",
    "                {\"type\": \"image\",\"image\": image}\n",
    "            ]}\n",
    "        ]\n",
    "        prompt = self.processor.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "        # 4. ç¼–ç å›¾æ–‡è¾“å…¥ï¼ˆæ³¨æ„ä¸è¦è®¾ç½® truncation æˆ– max_lengthï¼‰\n",
    "        inputs = self.processor(\n",
    "            text=prompt,\n",
    "            images=image,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"longest\",   # âœ… è‡ªåŠ¨å¯¹é½\n",
    "            truncation=False     # âœ… ä¸æˆªæ–­ä»»ä½• token\n",
    "        )\n",
    "\n",
    "        # 5. ç¼–ç æ ‡ç­¾\n",
    "        label_text = f\"Answer: {answer_letter}\\nExplanation: {sample['solution_lecture']}\"\n",
    "        tokenizer = self.processor.tokenizer\n",
    "        \n",
    "        input_len = inputs[\"input_ids\"].shape[1]\n",
    "        \n",
    "        label_ids = tokenizer(\n",
    "            label_text,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=input_len\n",
    "        )[\"input_ids\"]\n",
    "        label_ids[label_ids == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        # 6. è¿”å›é¡¹ï¼ˆç¡®ä¿ input_ids å’Œ attention_mask ç­‰é•¿ï¼‰\n",
    "        input_ids = inputs[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = inputs[\"attention_mask\"].squeeze(0)\n",
    "        if input_ids.shape != attention_mask.shape:\n",
    "            raise ValueError(f\"input_ids shape {input_ids.shape} â‰  attention_mask shape {attention_mask.shape}\")\n",
    "\n",
    "        result = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": label_ids.squeeze(0),\n",
    "            \"pixel_values\": inputs[\"pixel_values\"].squeeze(0),\n",
    "        }\n",
    "\n",
    "        if \"image_grid_thw\" in inputs:\n",
    "            result[\"image_grid_thw\"] = inputs[\"image_grid_thw\"].squeeze(0)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] input_ids: {input_ids.shape}\")\n",
    "            print(f\"[DEBUG] attention_mask: {attention_mask.shape}\")\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5519615c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# å‡è®¾ä½ å·²ç»æœ‰äº† data_listï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« imageï¼ˆè·¯å¾„æˆ–PILå¯¹è±¡ï¼‰ã€questionã€choicesã€hintã€answerã€solution_lecture\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-3B-Instruct\")\n",
    "train_dataset = QwenVLPrefixDataset(dataset_train, processor, debug=False)\n",
    "val_dataset = QwenVLPrefixDataset(dataset_val, processor, debug=False)\n",
    "dataloader = DataLoader(dataset_train, batch_size=6, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8434da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def qwen_vl_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    å¯è‡ªåŠ¨ pad çš„ collate å‡½æ•°ï¼Œé€‚é…ä¸åŒé•¿åº¦ input_ids / labelsã€‚\n",
    "    \"\"\"\n",
    "    def pad_tensor_list(tensor_list, pad_value=0):\n",
    "        return pad_sequence(tensor_list, batch_first=True, padding_value=pad_value)\n",
    "\n",
    "    input_ids = [item[\"input_ids\"] for item in batch]\n",
    "    attention_mask = [item[\"attention_mask\"] for item in batch]\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "    pixel_values = [item[\"pixel_values\"] for item in batch]  # é€šå¸¸ shape ä¸€è‡´ï¼Œå¯ç›´æ¥ stack\n",
    "    image_grid_thw = [item[\"image_grid_thw\"] for item in batch]  # é€šå¸¸ shape ä¸€è‡´ï¼Œå¯ç›´æ¥ stack\n",
    "\n",
    "    input_ids = pad_tensor_list(input_ids, pad_value=0)\n",
    "    attention_mask = pad_tensor_list(attention_mask, pad_value=0)\n",
    "    labels = pad_tensor_list(labels, pad_value=-100)  # å¯¹ labels padding ç”¨ -100 é¿å…å½±å“ loss\n",
    "    pixel_values = torch.stack(pixel_values)\n",
    "    image_grid_thw = torch.stack(image_grid_thw)\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        # \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels,\n",
    "        \"pixel_values\": pixel_values,\n",
    "        'image_grid_thw': image_grid_thw\n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79562971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== ç¬¬ä¸€ä¸ª batch çš„ç¬¬ä¸€ä¸ªæ ·æœ¬ ====\n",
      "input_ids shape: torch.Size([162])\n",
      "labels shape: torch.Size([162])\n",
      "pixel_values shape: torch.Size([256, 1176])\n",
      "image_grid_thw shape: torch.Size([3])\n",
      "\n",
      "--- è§£ç åçš„ input_ids ---\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Question: What is the name of the colony shown?\n",
      "Choices:\n",
      "A. Maryland\n",
      "B. New Hampshire\n",
      "C. Rhode Island\n",
      "D. Vermont\n",
      "\n",
      "Here is a image:\n",
      "Please select the correct answer. Then, explain your reasoning in detail. Make sure your explanation is at least three sentences long, refers to specific data from the image, and shows your step-by-step logic.\n",
      "assistant\n",
      "\n",
      "\n",
      "--- è§£ç åçš„ labels ---\n",
      "Answer: B\n",
      "Explanation: The colony is New Hampshire.\n",
      "During the colonial era, New Hampshire and New York both claimed the territory that would later become the state of Vermont. Vermont was never its own colony.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# æ­£ç¡®ä½¿ç”¨ collate_fn\n",
    "\n",
    "dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=qwen_vl_collate_fn)\n",
    "\n",
    "# è·å–ç¬¬ä¸€ä¸ª batch\n",
    "first_batch = next(iter(dataloader))\n",
    "\n",
    "# æŸ¥çœ‹ç¬¬ä¸€ä¸ªæ ·æœ¬çš„ç»“æ„\n",
    "print(\"==== ç¬¬ä¸€ä¸ª batch çš„ç¬¬ä¸€ä¸ªæ ·æœ¬ ====\")\n",
    "print(f\"input_ids shape: {first_batch['input_ids'][0].shape}\")\n",
    "# print(f\"attention_mask shape: {first_batch['attention_mask'][0].shape}\")\n",
    "print(f\"labels shape: {first_batch['labels'][0].shape}\")\n",
    "print(f\"pixel_values shape: {first_batch['pixel_values'][0].shape}\")\n",
    "print(f\"image_grid_thw shape: {first_batch['image_grid_thw'][0].shape}\")\n",
    "\n",
    "# å¯é€‰ï¼šæŸ¥çœ‹æ–‡æœ¬å†…å®¹ï¼ˆéœ€è¦ tokenizerï¼‰\n",
    "tokenizer = processor.tokenizer\n",
    "decoded_input = tokenizer.decode(first_batch['input_ids'][0], skip_special_tokens=True)\n",
    "decoded_label = tokenizer.decode(\n",
    "    [id for id in first_batch['labels'][0].tolist() if id != -100],\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(\"\\n--- è§£ç åçš„ input_ids ---\")\n",
    "print(decoded_input)\n",
    "\n",
    "print(\"\\n--- è§£ç åçš„ labels ---\")\n",
    "print(decoded_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fbbc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-3B-Instruct\", device_map=\"auto\", torch_dtype=torch.bfloat16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c7ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = PrefixTuningConfig(\n",
    "    task_type='CAUSAL_LM',\n",
    "    inference_mode=False,\n",
    "    num_virtual_tokens=12,\n",
    "    prefix_projection=True\n",
    ")\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "796f8352",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):  # å±è”½ num_items_in_batch\n",
    "        if \"num_items_in_batch\" in kwargs:\n",
    "            kwargs.pop(\"num_items_in_batch\")\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14060ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge import Rouge\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "\n",
    "def parse_output(output):\n",
    "    output = output.strip()\n",
    "\n",
    "    # case 1: \"Answer: A Explanation: xxx\"\n",
    "    match = re.search(r\"Answer[:ï¼š]?\\s*([A-D])\\b.*?Explanation[:ï¼š]?\\s*(.+)\", output, re.DOTALL)\n",
    "    if match:\n",
    "        answer = ord(match.group(1)) - 65\n",
    "        explanation = match.group(2).strip()\n",
    "        return answer, explanation\n",
    "\n",
    "    # case 2: \"A Explanation: xxx\"\n",
    "    match = re.match(r\"\\b([A-D])\\s*Explanation[:ï¼š]?\\s*(.+)\", output, re.DOTALL)\n",
    "    if match:\n",
    "        answer = ord(match.group(1)) - 65\n",
    "        explanation = match.group(2).strip()\n",
    "        return answer, explanation\n",
    "\n",
    "    # case 3: \"A. xxx\" or \"B: xxx\"\n",
    "    match = re.match(r\"\\b([A-D])[\\.:]\\s*(.+)\", output, re.DOTALL)\n",
    "    if match:\n",
    "        answer = ord(match.group(1)) - 65\n",
    "        explanation = match.group(2).strip()\n",
    "        return answer, explanation\n",
    "\n",
    "    # case 4: only one letter like \"C\"\n",
    "    match = re.match(r\"^\\s*([A-D])\\s*$\", output)\n",
    "    if match:\n",
    "        answer = ord(match.group(1)) - 65\n",
    "        return answer, \"\"\n",
    "\n",
    "    # fallback: try to find first capital letter A-D (unsafe)\n",
    "    match = re.search(r\"\\b([A-D])\\b\", output)\n",
    "    if match:\n",
    "        answer = ord(match.group(1)) - 65\n",
    "        explanation = output[match.end():].strip()\n",
    "        return answer, explanation\n",
    "\n",
    "    return -1, \"\"\n",
    "\n",
    "def keyword_overlap(pred, ref):\n",
    "    pred_keywords = set(pred.lower().split())\n",
    "    ref_keywords = set(ref.lower().split())\n",
    "    if not ref_keywords:\n",
    "        return 0.0\n",
    "    return len(pred_keywords & ref_keywords) / len(ref_keywords)\n",
    "\n",
    "MAX_LEN = 1024\n",
    "smoothie = SmoothingFunction().method4\n",
    "\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# ==== å…¨å±€è®¾ç½® ====\n",
    "MAX_LEN = 512\n",
    "smoothie = SmoothingFunction().method4\n",
    "global_rouge = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "\n",
    "# ==== Keyword Overlap ====\n",
    "def keyword_overlap(pred, ref):\n",
    "    pred_keywords = set(pred.lower().split())\n",
    "    ref_keywords = set(ref.lower().split())\n",
    "    if not ref_keywords:\n",
    "        return 0.0\n",
    "    return len(pred_keywords & ref_keywords) / len(ref_keywords)\n",
    "\n",
    "# ==== Metric å‡½æ•° ====\n",
    "def compute_metrics(eval_preds, tokenizer):\n",
    "    predictions = eval_preds.predictions\n",
    "    label_ids = eval_preds.label_ids\n",
    "    inputs = eval_preds.inputs if hasattr(eval_preds, \"inputs\") else None  # å¦‚æœä½ æƒ³ä¸€èµ·æ‰“å°è¾“å…¥\n",
    "\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "    if predictions.ndim == 3:\n",
    "        predictions = predictions.argmax(-1)\n",
    "\n",
    "    decoded_preds = []\n",
    "    decoded_labels = []\n",
    "\n",
    "    print(\"\\n================= Sample Predictions =================\")\n",
    "    for i, (pred_ids, label) in enumerate(zip(predictions, label_ids)):\n",
    "        try:\n",
    "            label = [id for id in label if id != -100]\n",
    "            if hasattr(pred_ids, \"tolist\"):\n",
    "                pred_ids = pred_ids.tolist()\n",
    "\n",
    "            decoded_pred = tokenizer.decode(pred_ids, skip_special_tokens=True)\n",
    "            decoded_label = tokenizer.decode(label, skip_special_tokens=True)\n",
    "\n",
    "            decoded_pred = decoded_pred.encode(\"utf-8\", errors=\"ignore\").decode(\"utf-8\", errors=\"ignore\")[:MAX_LEN].strip()\n",
    "            decoded_label = decoded_label.encode(\"utf-8\", errors=\"ignore\").decode(\"utf-8\", errors=\"ignore\")[:MAX_LEN].strip()\n",
    "\n",
    "            if not decoded_pred or not decoded_label:\n",
    "                continue\n",
    "\n",
    "            decoded_preds.append(decoded_pred)\n",
    "            decoded_labels.append(decoded_label)\n",
    "\n",
    "            # ğŸ‘‰ æ‰“å°è¾“å…¥è¾“å‡ºå¯¹ï¼ˆå¯é€‰åŠ è¾“å…¥ï¼‰\n",
    "            print(f\"[{i}]\")\n",
    "            if inputs is not None and \"input_ids\" in inputs:\n",
    "                input_ids = inputs[\"input_ids\"][i].tolist()\n",
    "                decoded_input = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "                print(f\"ğŸŸ¡ Input: {decoded_input}\")\n",
    "            print(f\"ğŸ”µ Label: {decoded_label}\")\n",
    "            print(f\"ğŸŸ¢ Pred : {decoded_pred}\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[âŒ Decode error at sample {i}] {e}\")\n",
    "            continue\n",
    "\n",
    "    # === Metric ===\n",
    "    bleu1_scores = []\n",
    "    bleu4_scores = []\n",
    "    rouge_l_scores = []\n",
    "    keyword_overlaps = []\n",
    "    choice_correct = []\n",
    "\n",
    "    for i, (pred, label) in enumerate(zip(decoded_preds, decoded_labels)):\n",
    "        try:\n",
    "            reference = label.split()\n",
    "            candidate = pred.split()\n",
    "\n",
    "            if not reference or not candidate:\n",
    "                continue\n",
    "\n",
    "            bleu1 = sentence_bleu([reference], candidate, weights=(1, 0, 0, 0), smoothing_function=smoothie)\n",
    "            bleu4 = sentence_bleu([reference], candidate, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie)\n",
    "            rouge_l = global_rouge.score(label, pred)[\"rougeL\"].fmeasure\n",
    "            keyword_acc = keyword_overlap(pred, label)\n",
    "\n",
    "            pred_choice, _ = parse_output(pred)\n",
    "            label_choice, _ = parse_output(label)\n",
    "            correct = int(pred_choice == label_choice and pred_choice != -1)\n",
    "\n",
    "            bleu1_scores.append(bleu1)\n",
    "            bleu4_scores.append(bleu4)\n",
    "            rouge_l_scores.append(rouge_l)\n",
    "            keyword_overlaps.append(keyword_acc)\n",
    "            choice_correct.append(correct)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[âŒ Metric error at sample {i}] {e}\")\n",
    "            continue\n",
    "\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return {\n",
    "        \"BLEU-1\": np.mean(bleu1_scores) if bleu1_scores else 0.0,\n",
    "        \"BLEU-4\": np.mean(bleu4_scores) if bleu4_scores else 0.0,\n",
    "        \"ROUGE-L\": np.mean(rouge_l_scores) if rouge_l_scores else 0.0,\n",
    "        \"KeywordOverlap\": np.mean(keyword_overlaps) if keyword_overlaps else 0.0,\n",
    "        \"ChoiceAccuracy\": np.mean(choice_correct) if choice_correct else 0.0,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3586bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-3B-Instruct\")\n",
    "small_train_dataset=dataset_train\n",
    "small_val_dataset=dataset_val\n",
    "train_dataset = QwenVLPrefixDataset(small_train_dataset, processor, debug=False)\n",
    "val_dataset = QwenVLPrefixDataset(small_val_dataset, processor, debug=False)    \n",
    "# dataloader = DataLoader(train_dataset, batch_size=6, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "804580d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "[codecarbon ERROR @ 18:14:06] Error: Another instance of codecarbon is probably running as we find `/tmp/.codecarbon.lock`. Turn off the other instance to be able to run this one or use `allow_multiple_runs` or delete the file. Exiting.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qwen2.5vl-prefix2.03B\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=1, \n",
    "    dataloader_num_workers=0,\n",
    "    eval_accumulation_steps=1,\n",
    "    learning_rate=5e-4,\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    bf16=True,  # å¦‚æœä½¿ç”¨çš„æ˜¯æ”¯æŒ bfloat16 çš„ GPUï¼Œå¯æ”¹ä¸º bf16=True\n",
    "    gradient_accumulation_steps=4,\n",
    "    do_eval=True,\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=qwen_vl_collate_fn,\n",
    "    compute_metrics=lambda p: compute_metrics(p, tokenizer=processor.tokenizer)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21c2d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef8c9fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4aacb19a36495f8f17ed5ff7a84401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForVision2Seq\n",
    "from peft import PeftModel\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# ç¬¬ä¸€æ­¥ï¼šåŠ è½½ base æ¨¡å‹ï¼ˆè§†è§‰è¯­è¨€æ¨¡å‹ï¼‰\n",
    "base_model =  AutoModelForVision2Seq.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-3B-Instruct\",\n",
    "    device_map={\"\": device},\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    ")\n",
    "\n",
    "# ç¬¬äºŒæ­¥ï¼šåŠ è½½ Prefix Tuning æƒé‡\n",
    "prefix_path = \"./qwen2.5vl-prefix2.03B/checkpoint-1360\"  # æ¯”å¦‚ checkpoint-1360\n",
    "model = PeftModel.from_pretrained(base_model, prefix_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "430fbddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc6652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e5e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01923cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_step_by_step(model, dataset, tokenizer, collate_fn, batch_size=1, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "\n",
    "    bleu1_scores = []\n",
    "    bleu4_scores = []\n",
    "    rouge_l_scores = []\n",
    "    keyword_overlaps = []\n",
    "    choice_correct = []\n",
    "\n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "        # Move to device\n",
    "        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        # è·å– logits â†’ token ids\n",
    "        if hasattr(outputs, \"logits\"):\n",
    "            pred_ids = outputs.logits.argmax(-1).detach().cpu().tolist()\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        label_ids = batch[\"labels\"].detach().cpu().tolist()\n",
    "\n",
    "        # decode\n",
    "        for j, (pred, label) in enumerate(zip(pred_ids, label_ids)):\n",
    "            pred_text = tokenizer.decode(pred, skip_special_tokens=True)\n",
    "            label_text = tokenizer.decode([id for id in label if id != -100], skip_special_tokens=True)\n",
    "\n",
    "            ref = label_text.split()\n",
    "            cand = pred_text.split()\n",
    "            if not ref or not cand:\n",
    "                continue\n",
    "\n",
    "            # è®¡ç®—å„é¡¹æŒ‡æ ‡\n",
    "            bleu1 = sentence_bleu([ref], cand, weights=(1, 0, 0, 0), smoothing_function=smoothie)\n",
    "            bleu4 = sentence_bleu([ref], cand, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie)\n",
    "            rouge_l = global_rouge.score(label_text, pred_text)[\"rougeL\"].fmeasure\n",
    "            keyword_acc = keyword_overlap(pred_text, label_text)\n",
    "\n",
    "            pred_choice, _ = parse_output(pred_text)\n",
    "            label_choice, _ = parse_output(label_text)\n",
    "            correct = int(pred_choice == label_choice and pred_choice != -1)\n",
    "\n",
    "            # è®°å½•\n",
    "            bleu1_scores.append(bleu1)\n",
    "            bleu4_scores.append(bleu4)\n",
    "            rouge_l_scores.append(rouge_l)\n",
    "            keyword_overlaps.append(keyword_acc)\n",
    "            choice_correct.append(correct)\n",
    "\n",
    "            # æ¯æ¡è¾“å‡ºä¸€æ¡ï¼Œæ¸…ç©ºä¸Šä¸€æ¡\n",
    "            clear_output(wait=True)\n",
    "            print(f\"\\n[Sample {i * batch_size + j}]\")\n",
    "            print(f\"ğŸ”¹BLEU-1: {bleu1:.4f}  BLEU-4: {bleu4:.4f}\")\n",
    "            print(f\"ğŸ”¹ROUGE-L: {rouge_l:.4f}  KeywordOverlap: {keyword_acc:.4f}\")\n",
    "            print(f\"ğŸ”¹ChoiceAccuracy: {correct}\")\n",
    "            print(f\"ğŸ”¸Reference: {label_text}\")\n",
    "            print(f\"ğŸ”¸Prediction: {pred_text}\")\n",
    "\n",
    "    # è¿”å›å¹³å‡åˆ†\n",
    "    return {\n",
    "        \"BLEU-1\": np.mean(bleu1_scores) if bleu1_scores else 0.0,\n",
    "        \"BLEU-4\": np.mean(bleu4_scores) if bleu4_scores else 0.0,\n",
    "        \"ROUGE-L\": np.mean(rouge_l_scores) if rouge_l_scores else 0.0,\n",
    "        \"KeywordOverlap\": np.mean(keyword_overlaps) if keyword_overlaps else 0.0,\n",
    "        \"ChoiceAccuracy\": np.mean(choice_correct) if choice_correct else 0.0,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4e7e0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1429/1429 [02:35<00:00,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample 1428]\n",
      "ğŸ”¹BLEU-1: 0.1371  BLEU-4: 0.0169\n",
      "ğŸ”¹ROUGE-L: 0.1857  KeywordOverlap: 0.3000\n",
      "ğŸ”¹ChoiceAccuracy: 0\n",
      "ğŸ”¸Reference: Answer: A\n",
      "Explanation: The bulldozer pushes the loose dirt. The direction of the push is away from the bulldozer.\n",
      "\n",
      "A force is a push or a pull that one object applies to another. Every force has a direction.\n",
      "The direction of a push is away from the object that is pushing.\n",
      "The direction of a pull is toward the object that is pulling.\n",
      "ğŸ”¸Prediction: : B\n",
      "Explanation: Look is the capital of the... rose. it.. is. the. a force push force direction direction a direction direction direction direction direction. a a direction push direction direction of a a a push direction. direction direction a a of a of a a direction a a a a a a a a a a object. a of a object. a of the direction a a a direction a a is a a a a a a a the a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a of a a a a a a a a a a a a a a a a a a a a of a a a a a a a a a a a a a a a a a a a a a a a force force a a force force force force a force a direction a The force direction a a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU-1': 0.22413028480130578,\n",
       " 'BLEU-4': 0.07225036086702381,\n",
       " 'ROUGE-L': 0.2542470650297796,\n",
       " 'KeywordOverlap': 0.3902395612075573,\n",
       " 'ChoiceAccuracy': 0.3547935619314206}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_step_by_step(model, val_dataset, processor.tokenizer, qwen_vl_collate_fn, batch_size=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
