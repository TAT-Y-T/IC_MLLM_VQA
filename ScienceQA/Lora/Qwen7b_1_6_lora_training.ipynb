{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a382b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from peft import get_peft_model, PrefixTuningConfig, TaskType\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49cd4aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 筛选后的样本数量: 4349\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "def build_filtered_dataset(dataset_name='derek-thomas/ScienceQA',\n",
    "                           split='train',\n",
    "                           keep_grades='1-6'):\n",
    "    \"\"\"\n",
    "    构建按年级和图像存在性过滤的数据集。\n",
    "\n",
    "    参数:\n",
    "        dataset_name (str): 数据集名称，例如 'derek-thomas/ScienceQA'。\n",
    "        split (str): 数据分割，例如 'train', 'test', 'validation'。\n",
    "        keep_grades (str or None): 筛选的年级段：\"1-6\"、\"7-12\" 或 None 表示不过滤。\n",
    "\n",
    "    返回:\n",
    "        List[Dict]: 筛选后的样本列表。\n",
    "    \"\"\"\n",
    "\n",
    "    def is_grade_allowed(grade_str):\n",
    "        if keep_grades is None:\n",
    "            return True\n",
    "        try:\n",
    "            grade_num = int(grade_str.replace(\"grade\", \"\"))\n",
    "            if keep_grades == \"1-6\":\n",
    "                return 1 <= grade_num <= 6\n",
    "            elif keep_grades == \"7-12\":\n",
    "                return 7 <= grade_num <= 12\n",
    "        except:\n",
    "            return False\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "    data = load_dataset(dataset_name, split=split)\n",
    "    dataset = []\n",
    "\n",
    "    for i, sample in enumerate(data):\n",
    "        try:\n",
    "            if sample.get('question') is None:\n",
    "                continue\n",
    "            \n",
    "            if sample.get(\"image\", None) is None:\n",
    "                continue\n",
    "\n",
    "            if not is_grade_allowed(sample.get(\"grade\", \"\")):\n",
    "                continue\n",
    "\n",
    "            solution = sample.get(\"solution\", \"\")\n",
    "            lecture = sample.get(\"lecture\", \"\")\n",
    "            solution_lecture = f\"{solution}\\n\\n{lecture}\".strip()\n",
    "            \n",
    "            image = sample[\"image\"].convert(\"RGB\")\n",
    "            \n",
    "\n",
    "            # image = np.array(image)\n",
    "            # image = torch.tensor(image).permute(2, 0, 1)  # shape: (C, H, W)\n",
    "            dataset.append({\n",
    "                \"image\": image, \n",
    "                \"question\": sample[\"question\"],\n",
    "                \"choices\": sample[\"choices\"],\n",
    "                \"hint\": sample[\"hint\"],\n",
    "                \"answer\": sample[\"answer\"],\n",
    "                \"solution_lecture\": solution_lecture,\n",
    "                'grade':sample[\"grade\"],\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"跳过第 {i} 个样本，错误：{e}\")\n",
    "            continue\n",
    "    return dataset\n",
    "\n",
    "dataset_train = build_filtered_dataset(split='train', keep_grades='1-6')\n",
    "print(f\"\\n✅ 筛选后的样本数量: {len(dataset_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eebb75bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 筛选后的样本数量: 1481\n"
     ]
    }
   ],
   "source": [
    "dataset_val = build_filtered_dataset(split='validation', keep_grades='1-6')\n",
    "print(f\"\\n✅ 筛选后的样本数量: {len(dataset_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f98ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which property matches this object?\n",
      "Choices: ['sticky', 'colorful']\n",
      "Hint: Select the better answer.\n",
      "Grade: grade2\n",
      "Answer: 0\n",
      "Explanation: Look at the object.\n",
      "Think about each property.\n",
      "A colorful object has one or more bright colors. The tape is not colorful.\n",
      "A sticky object can stick to other things. The tape is sticky.\n",
      "\n",
      "An object has different properties. A property of an object can tell you how it looks, feels, tastes, or smells.\n",
      "Image type: <class 'PIL.Image.Image'>\n"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    "\n",
    "sample_1 = choice(dataset_train)\n",
    "print(f\"Question: {sample_1['question']}\")\n",
    "print(f\"Choices: {sample_1['choices']}\")\n",
    "print(f\"Hint: {sample_1['hint']}\")\n",
    "print(f\"Grade: {sample_1['grade']}\")\n",
    "print(f\"Answer: {sample_1['answer']}\")\n",
    "print(f\"Explanation: {sample_1['solution_lecture']}\")\n",
    "print(f\"Image type: {type(sample_1['image'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a5efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "class QwenVLPrefixDataset(Dataset):\n",
    "    def __init__(self, data_list, processor, debug=False):\n",
    "        self.data_list = data_list\n",
    "        self.processor = processor\n",
    "        self.debug = debug\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data_list[idx]\n",
    "        return self.build_training_sample(sample)\n",
    "\n",
    "    def build_training_sample(self, sample):\n",
    "        # 1. 构造答案\n",
    "        if isinstance(sample[\"answer\"], int):\n",
    "            answer_index = sample[\"answer\"]\n",
    "        else:\n",
    "            answer_index = sample[\"choices\"].index(sample[\"answer\"])\n",
    "        answer_letter = chr(65 + answer_index)\n",
    "\n",
    "        # 2. 构建问题内容\n",
    "        question_text = f\"Question: {sample['question']}\\nChoices:\\n\"\n",
    "        for idx, choice in enumerate(sample[\"choices\"]):\n",
    "            question_text += f\"{chr(65 + idx)}. {choice}\\n\"\n",
    "        if sample.get(\"hint\"):\n",
    "            question_text += f\"\\nHint: {sample['hint']}\\n\"\n",
    "        question_text += (\n",
    "            \"\\nHere is a image:\\n\"\n",
    "            \"Please select the correct answer. Then, explain your reasoning in detail. \"\n",
    "            \"Make sure your explanation is at least three sentences long, \"\n",
    "            \"refers to specific data from the image, and shows your step-by-step logic.\"\n",
    "        )\n",
    "\n",
    "        # 3. 构建 label 文本（拼接到 prompt 后）\n",
    "        label_text = f\"\\nAnswer: {answer_letter}\\nExplanation: {sample['solution_lecture']}\"\n",
    "\n",
    "        # 4. 图像处理\n",
    "        image = sample[\"image\"]\n",
    "        if not isinstance(image, Image.Image):\n",
    "            raise ValueError(\"image must be a PIL.Image.Image\")\n",
    "        image = image.convert(\"RGB\").resize((224, 224))\n",
    "\n",
    "        # 5. 构造完整对话 + 图像输入\n",
    "        chat = [\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": question_text},\n",
    "                {\"type\": \"image\", \"image\": image}\n",
    "            ]},\n",
    "            {\"role\": \"assistant\", \"content\": label_text}\n",
    "        ]\n",
    "\n",
    "        # 6. 编码图文输入（注意：一体编码 prompt+label）\n",
    "        text = self.processor.apply_chat_template(chat, tokenize=False, add_generation_prompt=False)\n",
    "        inputs = self.processor(\n",
    "            text=text,\n",
    "            images=image,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=False,\n",
    "            truncation=False\n",
    "        )\n",
    "\n",
    "        # 7. 构造 labels —— 用 input_ids 克隆，并 mask 掉前面的 prompt\n",
    "        input_ids = inputs[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = inputs[\"attention_mask\"].squeeze(0)\n",
    "\n",
    "        # 找到 label 的起始位置：用 processor 再只 encode user 部分计算长度\n",
    "        user_text_only = self.processor.apply_chat_template(chat[:1], tokenize=False, add_generation_prompt=False)\n",
    "        user_input_ids = self.processor.tokenizer(user_text_only, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"][0]\n",
    "        user_len = user_input_ids.shape[-1]\n",
    "\n",
    "        labels = input_ids.clone()\n",
    "        labels[:user_len] = -100  # mask prompt 部分\n",
    "\n",
    "        result = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels,\n",
    "            \"pixel_values\": inputs[\"pixel_values\"].squeeze(0),\n",
    "        }\n",
    "\n",
    "        if \"image_grid_thw\" in inputs:\n",
    "            result[\"image_grid_thw\"] = inputs[\"image_grid_thw\"].squeeze(0)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] input_ids.shape: {input_ids.shape}\")\n",
    "            print(f\"[DEBUG] labels.shape: {labels.shape}\")\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5519615c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\")\n",
    "train_dataset = QwenVLPrefixDataset(dataset_train, processor, debug=False)\n",
    "dataloader = DataLoader(dataset_train, batch_size=6, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8434da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def qwen_vl_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collate 函数，用于 QwenVL 多模态模型训练。\n",
    "    自动对 input_ids / labels 进行 padding，\n",
    "    pixel_values 和 image_grid_thw 直接 stack（假设 shape 一致）。\n",
    "    \"\"\"\n",
    "    def pad_tensor_list(tensor_list, pad_value=0):\n",
    "        return pad_sequence(tensor_list, batch_first=True, padding_value=pad_value)\n",
    "\n",
    "    input_ids = [item[\"input_ids\"] for item in batch]\n",
    "    attention_mask = [item[\"attention_mask\"] for item in batch]\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "\n",
    "    # 部分模型 forward 需要 attention_mask，尽管有些模型不强依赖，也建议保留\n",
    "    input_ids = pad_tensor_list(input_ids, pad_value=0)\n",
    "    attention_mask = pad_tensor_list(attention_mask, pad_value=0)\n",
    "    labels = pad_tensor_list(labels, pad_value=-100)  # 避免 loss 对 pad token 计算\n",
    "\n",
    "    # 多模态部分\n",
    "    pixel_values = torch.stack([item[\"pixel_values\"] for item in batch])\n",
    "    \n",
    "    # 可选：容错处理 image_grid_thw（有些模型可能没有）\n",
    "    if \"image_grid_thw\" in batch[0]:\n",
    "        image_grid_thw = torch.stack([item[\"image_grid_thw\"] for item in batch])\n",
    "    else:\n",
    "        image_grid_thw = None\n",
    "\n",
    "    # 构造返回字典\n",
    "    result = {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels,\n",
    "        \"pixel_values\": pixel_values,\n",
    "    }\n",
    "    # print(f\"input_ids shape: {input_ids.shape}, attention_mask shape: {attention_mask.shape}, labels shape: {labels.shape}, pixel_values shape: {pixel_values.shape}\")\n",
    "    if image_grid_thw is not None:\n",
    "        result[\"image_grid_thw\"] = image_grid_thw\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79562971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== 第一个 batch 的第一个样本 ====\n",
      "input_ids shape: torch.Size([270])\n",
      "attention_mask shape: torch.Size([270])\n",
      "labels shape: torch.Size([270])\n",
      "pixel_values shape: torch.Size([256, 1176])\n",
      "image_grid_thw shape: torch.Size([3])\n",
      "\n",
      "--- 解码后的 input_ids ---\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Question: Which of these states is farthest north?\n",
      "Choices:\n",
      "A. West Virginia\n",
      "B. Louisiana\n",
      "C. Arizona\n",
      "D. Oklahoma\n",
      "\n",
      "Here is a image:\n",
      "Please select the correct answer. Then, explain your reasoning in detail. Make sure your explanation is at least three sentences long, refers to specific data from the image, and shows your step-by-step logic.\n",
      "assistant\n",
      "\n",
      "Answer: A\n",
      "Explanation: To find the answer, look at the compass rose. Look at which way the north arrow is pointing. West Virginia is farthest north.\n",
      "\n",
      "Maps have four cardinal directions, or main directions. Those directions are north, south, east, and west.\n",
      "A compass rose is a set of arrows that point to the cardinal directions. A compass rose usually shows only the first letter of each cardinal direction.\n",
      "The north arrow points to the North Pole. On most maps, north is at the top of the map.\n",
      "\n",
      "\n",
      "--- 解码后的 labels ---\n",
      "\n",
      "assistant\n",
      "\n",
      "Answer: A\n",
      "Explanation: To find the answer, look at the compass rose. Look at which way the north arrow is pointing. West Virginia is farthest north.\n",
      "\n",
      "Maps have four cardinal directions, or main directions. Those directions are north, south, east, and west.\n",
      "A compass rose is a set of arrows that point to the cardinal directions. A compass rose usually shows only the first letter of each cardinal direction.\n",
      "The north arrow points to the North Pole. On most maps, north is at the top of the map.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 正确使用 collate_fn\n",
    "dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False, collate_fn=qwen_vl_collate_fn)\n",
    "\n",
    "# 获取第一个 batch\n",
    "first_batch = next(iter(dataloader))\n",
    "\n",
    "# 查看第一个样本的结构\n",
    "n = 0\n",
    "print(\"==== 第一个 batch 的第一个样本 ====\")\n",
    "print(f\"input_ids shape: {first_batch['input_ids'][n].shape}\")\n",
    "print(f\"attention_mask shape: {first_batch['attention_mask'][0].shape}\")\n",
    "print(f\"labels shape: {first_batch['labels'][n].shape}\")\n",
    "print(f\"pixel_values shape: {first_batch['pixel_values'][n].shape}\")\n",
    "print(f\"image_grid_thw shape: {first_batch['image_grid_thw'][n].shape}\")\n",
    "\n",
    "# 可选：查看文本内容（需要 tokenizer）\n",
    "tokenizer = processor.tokenizer\n",
    "decoded_input = tokenizer.decode(first_batch['input_ids'][n], skip_special_tokens=True)\n",
    "decoded_label = tokenizer.decode(\n",
    "    [id for id in first_batch['labels'][n].tolist() if id != -100],\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(\"\\n--- 解码后的 input_ids ---\")\n",
    "print(decoded_input)\n",
    "\n",
    "print(\"\\n--- 解码后的 labels ---\")\n",
    "print(decoded_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23fbbc6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30aa2665d7f48628c5cc4ca04460171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-7B-Instruct\", device_map=\"auto\", torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8c7ad94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,261,568 || all params: 8,293,428,224 || trainable%: 0.0152\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,  # 对于 Qwen 这类生成模型，使用 CAUSAL_LM\n",
    "    inference_mode=False,          # 表示用于训练，不是推理\n",
    "    r=4,                           # LoRA 秩，越大可训练参数越多（常见：4, 8, 16）\n",
    "    lora_alpha=8,                 # 缩放因子，通常与 r 同阶或更大\n",
    "    lora_dropout=0.1,              # dropout，防止过拟合\n",
    "    target_modules=[\"q_proj\", \"v_proj\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "796f8352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        kwargs.pop(\"num_items_in_batch\", None)\n",
    "\n",
    "        try:\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs.loss\n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e).lower():\n",
    "                step = self.state.global_step\n",
    "                print(f\"\\n❌ [OOM at step {step}] Skipping this batch.\")\n",
    "                input_ids = inputs.get(\"input_ids\")\n",
    "                labels = inputs.get(\"labels\")\n",
    "\n",
    "                if input_ids is not None:\n",
    "                    print(f\"    input_ids shape: {input_ids.shape}\")\n",
    "                if labels is not None:\n",
    "                    print(f\"    labels shape: {labels.shape}\")\n",
    "\n",
    "                # 清理显存\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                # === ✅ 保存当前 checkpoint ===\n",
    "                oom_ckpt_dir = os.path.join(self.args.output_dir, f\"checkpoint-oom-step-{step}\")\n",
    "                print(f\"💾 Saving checkpoint due to OOM at: {oom_ckpt_dir}\")\n",
    "                self.save_model(oom_ckpt_dir)\n",
    "\n",
    "                dummy_loss = torch.tensor(0.0, requires_grad=True).to(model.device)\n",
    "                return (dummy_loss, None) if return_outputs else dummy_loss\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14060ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge import Rouge\n",
    "\n",
    "def parse_output(output: str):\n",
    "    \"\"\"\n",
    "    提取选择题答案和解释文本，容错支持 Answer: A, A., A: 等。\n",
    "    支持选项 A-F。\n",
    "    返回 answer: int (0~5 对应 A-F), explanation: str\n",
    "    \"\"\"\n",
    "    output = output.strip()\n",
    "\n",
    "    # 优先匹配 Answer: A 等格式\n",
    "    answer_match = re.search(r\"(?i)\\banswer\\s*[:\\-]?\\s*([A-F])\\b\", output)\n",
    "    if not answer_match:\n",
    "        # 回退匹配 A. / A: / A- 等格式\n",
    "        answer_match = re.search(r\"\\b([A-F])[\\.\\:\\-]\", output)\n",
    "\n",
    "    if answer_match:\n",
    "        choice_char = answer_match.group(1).upper()\n",
    "        answer = ord(choice_char) - ord(\"A\")\n",
    "    else:\n",
    "        answer = -1\n",
    "\n",
    "    explanation = \"\"\n",
    "    if answer_match:\n",
    "        idx = output.find(answer_match.group(0))\n",
    "        if idx != -1:\n",
    "            explanation = output[idx + len(answer_match.group(0)):].strip()\n",
    "\n",
    "    return answer, explanation\n",
    "\n",
    "\n",
    "def keyword_overlap(pred, ref):\n",
    "    pred_keywords = set(pred.lower().split())\n",
    "    ref_keywords = set(ref.lower().split())\n",
    "    if not ref_keywords:\n",
    "        return 0.0\n",
    "    return len(pred_keywords & ref_keywords) / len(ref_keywords)\n",
    "\n",
    "def compute_metrics(eval_preds, tokenizer):\n",
    "    predictions = eval_preds.predictions\n",
    "    label_ids = eval_preds.label_ids\n",
    "\n",
    "    # 如果 predictions 是 tuple（例如包含 logits），取第一个作为 token ids\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "\n",
    "    # 如果是 logits（形如 [batch, seq_len, vocab_size]），则 argmax 得到 token ids\n",
    "    if predictions.ndim == 3:\n",
    "        predictions = predictions.argmax(-1)\n",
    "\n",
    "    decoded_preds = []\n",
    "    decoded_labels = []\n",
    "\n",
    "    for pred_ids, label in zip(predictions, label_ids):\n",
    "        label = [id for id in label if id != -100]\n",
    "        decoded_pred = tokenizer.decode(pred_ids, skip_special_tokens=True)\n",
    "        decoded_label = tokenizer.decode(label, skip_special_tokens=True)\n",
    "\n",
    "        decoded_preds.append(decoded_pred.strip())\n",
    "        decoded_labels.append(decoded_label.strip())\n",
    "\n",
    "    # 打印第一个样本的预测和标签\n",
    "    # print(\"\\n==== 示例输出 ====\")\n",
    "    # print(\"预测：\", decoded_preds[0])\n",
    "    # print(\"标签：\", decoded_labels[0])\n",
    "\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    bleu1_scores = []\n",
    "    bleu4_scores = []\n",
    "    rouge_l_scores = []\n",
    "    keyword_overlaps = []\n",
    "    choice_correct = []\n",
    "\n",
    "    rouge = Rouge()\n",
    "\n",
    "    for pred, label in zip(decoded_preds, decoded_labels):\n",
    "        reference = label.split()\n",
    "        candidate = pred.split()\n",
    "\n",
    "        # BLEU-1 和 BLEU-4\n",
    "        bleu1 = sentence_bleu([reference], candidate, weights=(1, 0, 0, 0), smoothing_function=smoothie)\n",
    "        bleu4 = sentence_bleu([reference], candidate, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie)\n",
    "        bleu1_scores.append(bleu1)\n",
    "        bleu4_scores.append(bleu4)\n",
    "\n",
    "        # ROUGE-L\n",
    "        try:\n",
    "            rouge_l = rouge.get_scores(pred, label)[0]['rouge-l']['f']\n",
    "        except ValueError:\n",
    "            rouge_l = 0.0\n",
    "        rouge_l_scores.append(rouge_l)\n",
    "\n",
    "        # Keyword overlap\n",
    "        keyword_acc = keyword_overlap(pred, label)\n",
    "        keyword_overlaps.append(keyword_acc)\n",
    "\n",
    "        # Choice accuracy\n",
    "        pred_choice, _ = parse_output(pred)\n",
    "        label_choice, _ = parse_output(label)\n",
    "        is_correct = (pred_choice == label_choice) and (pred_choice != -1)\n",
    "        choice_correct.append(int(is_correct))\n",
    "\n",
    "    return {\n",
    "        \"BLEU-1\": np.mean(bleu1_scores),\n",
    "        \"BLEU-4\": np.mean(bleu4_scores),\n",
    "        \"ROUGE-L\": np.mean(rouge_l_scores),\n",
    "        \"KeywordOverlap\": np.mean(keyword_overlaps),\n",
    "        \"ChoiceAccuracy\": np.mean(choice_correct),\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3586bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\")\n",
    "small_train_dataset=dataset_train[:4000]\n",
    "small_val_dataset=dataset_val[:10]\n",
    "train_dataset = QwenVLPrefixDataset(small_train_dataset, processor, debug=False)\n",
    "val_dataset = QwenVLPrefixDataset(small_val_dataset, processor, debug=False)    \n",
    "# dataloader = DataLoader(train_dataset, batch_size=6, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "804580d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74734/258927189.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = CustomTrainer(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "[codecarbon ERROR @ 21:45:57] Error: Another instance of codecarbon is probably running as we find `/tmp/.codecarbon.lock`. Turn off the other instance to be able to run this one or use `allow_multiple_runs` or delete the file. Exiting.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qwen2.5vl-Lora1-6_0609\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=20, \n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=1, \n",
    "    dataloader_num_workers=0,\n",
    "    eval_accumulation_steps=1,\n",
    "    learning_rate=5e-4,\n",
    "    num_train_epochs=10,\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    bf16=True,  # 如果使用的是支持 bfloat16 的 GPU，可改为 bf16=True\n",
    "    gradient_accumulation_steps=4,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=qwen_vl_collate_fn,\n",
    "    compute_metrics=lambda p: compute_metrics(p, tokenizer=processor.tokenizer),\n",
    "    tokenizer=processor.tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a21c2d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 21:45:57] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5000/5000 16:30:43, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu-1</th>\n",
       "      <th>Bleu-4</th>\n",
       "      <th>Rouge-l</th>\n",
       "      <th>Keywordoverlap</th>\n",
       "      <th>Choiceaccuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.145100</td>\n",
       "      <td>3.421485</td>\n",
       "      <td>0.769401</td>\n",
       "      <td>0.638598</td>\n",
       "      <td>0.833992</td>\n",
       "      <td>0.890239</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.824100</td>\n",
       "      <td>2.675044</td>\n",
       "      <td>0.807427</td>\n",
       "      <td>0.714464</td>\n",
       "      <td>0.868479</td>\n",
       "      <td>0.943447</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.859800</td>\n",
       "      <td>2.592525</td>\n",
       "      <td>0.699326</td>\n",
       "      <td>0.638104</td>\n",
       "      <td>0.815012</td>\n",
       "      <td>0.947111</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.573900</td>\n",
       "      <td>2.562071</td>\n",
       "      <td>0.697333</td>\n",
       "      <td>0.645206</td>\n",
       "      <td>0.817938</td>\n",
       "      <td>0.957254</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.017300</td>\n",
       "      <td>2.543804</td>\n",
       "      <td>0.701093</td>\n",
       "      <td>0.654256</td>\n",
       "      <td>0.814732</td>\n",
       "      <td>0.957787</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.526300</td>\n",
       "      <td>2.531715</td>\n",
       "      <td>0.730261</td>\n",
       "      <td>0.685259</td>\n",
       "      <td>0.834239</td>\n",
       "      <td>0.959772</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.755200</td>\n",
       "      <td>2.527378</td>\n",
       "      <td>0.677545</td>\n",
       "      <td>0.638359</td>\n",
       "      <td>0.802461</td>\n",
       "      <td>0.959991</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.437900</td>\n",
       "      <td>2.520804</td>\n",
       "      <td>0.688065</td>\n",
       "      <td>0.645842</td>\n",
       "      <td>0.803065</td>\n",
       "      <td>0.960836</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.922100</td>\n",
       "      <td>2.515084</td>\n",
       "      <td>0.703237</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.813433</td>\n",
       "      <td>0.964153</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.045000</td>\n",
       "      <td>2.508202</td>\n",
       "      <td>0.652317</td>\n",
       "      <td>0.618417</td>\n",
       "      <td>0.786441</td>\n",
       "      <td>0.969981</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.924000</td>\n",
       "      <td>2.510101</td>\n",
       "      <td>0.658664</td>\n",
       "      <td>0.621789</td>\n",
       "      <td>0.784455</td>\n",
       "      <td>0.961819</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.775600</td>\n",
       "      <td>2.502433</td>\n",
       "      <td>0.645368</td>\n",
       "      <td>0.609764</td>\n",
       "      <td>0.788599</td>\n",
       "      <td>0.964335</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.847600</td>\n",
       "      <td>2.498094</td>\n",
       "      <td>0.667713</td>\n",
       "      <td>0.630274</td>\n",
       "      <td>0.795128</td>\n",
       "      <td>0.963185</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.880400</td>\n",
       "      <td>2.494579</td>\n",
       "      <td>0.669272</td>\n",
       "      <td>0.637133</td>\n",
       "      <td>0.790917</td>\n",
       "      <td>0.969396</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.053700</td>\n",
       "      <td>2.487792</td>\n",
       "      <td>0.659206</td>\n",
       "      <td>0.628936</td>\n",
       "      <td>0.794601</td>\n",
       "      <td>0.972481</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.514700</td>\n",
       "      <td>2.489377</td>\n",
       "      <td>0.635285</td>\n",
       "      <td>0.601752</td>\n",
       "      <td>0.775439</td>\n",
       "      <td>0.966711</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2.820100</td>\n",
       "      <td>2.486391</td>\n",
       "      <td>0.633127</td>\n",
       "      <td>0.602150</td>\n",
       "      <td>0.769558</td>\n",
       "      <td>0.969451</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.798100</td>\n",
       "      <td>2.488796</td>\n",
       "      <td>0.633158</td>\n",
       "      <td>0.600376</td>\n",
       "      <td>0.774466</td>\n",
       "      <td>0.966476</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2.855900</td>\n",
       "      <td>2.483410</td>\n",
       "      <td>0.605627</td>\n",
       "      <td>0.576403</td>\n",
       "      <td>0.747709</td>\n",
       "      <td>0.966971</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.905700</td>\n",
       "      <td>2.480220</td>\n",
       "      <td>0.612387</td>\n",
       "      <td>0.582652</td>\n",
       "      <td>0.755322</td>\n",
       "      <td>0.965487</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>2.708600</td>\n",
       "      <td>2.478549</td>\n",
       "      <td>0.606892</td>\n",
       "      <td>0.577798</td>\n",
       "      <td>0.756194</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.817000</td>\n",
       "      <td>2.472707</td>\n",
       "      <td>0.620539</td>\n",
       "      <td>0.589828</td>\n",
       "      <td>0.762658</td>\n",
       "      <td>0.967048</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.673100</td>\n",
       "      <td>2.474037</td>\n",
       "      <td>0.618236</td>\n",
       "      <td>0.589543</td>\n",
       "      <td>0.773120</td>\n",
       "      <td>0.967507</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.900500</td>\n",
       "      <td>2.471765</td>\n",
       "      <td>0.624105</td>\n",
       "      <td>0.597816</td>\n",
       "      <td>0.775923</td>\n",
       "      <td>0.973711</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.989900</td>\n",
       "      <td>2.480074</td>\n",
       "      <td>0.599842</td>\n",
       "      <td>0.572244</td>\n",
       "      <td>0.763534</td>\n",
       "      <td>0.969726</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.493100</td>\n",
       "      <td>2.479135</td>\n",
       "      <td>0.591787</td>\n",
       "      <td>0.561859</td>\n",
       "      <td>0.764705</td>\n",
       "      <td>0.969966</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.722900</td>\n",
       "      <td>2.469061</td>\n",
       "      <td>0.613076</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>0.781925</td>\n",
       "      <td>0.972460</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.755900</td>\n",
       "      <td>2.466633</td>\n",
       "      <td>0.603247</td>\n",
       "      <td>0.576468</td>\n",
       "      <td>0.762630</td>\n",
       "      <td>0.972954</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.694400</td>\n",
       "      <td>2.463495</td>\n",
       "      <td>0.618872</td>\n",
       "      <td>0.594270</td>\n",
       "      <td>0.773915</td>\n",
       "      <td>0.978157</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.855800</td>\n",
       "      <td>2.463556</td>\n",
       "      <td>0.611961</td>\n",
       "      <td>0.585053</td>\n",
       "      <td>0.768102</td>\n",
       "      <td>0.972460</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.877600</td>\n",
       "      <td>2.462615</td>\n",
       "      <td>0.627060</td>\n",
       "      <td>0.604152</td>\n",
       "      <td>0.765518</td>\n",
       "      <td>0.977375</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.700900</td>\n",
       "      <td>2.464656</td>\n",
       "      <td>0.627573</td>\n",
       "      <td>0.602133</td>\n",
       "      <td>0.774664</td>\n",
       "      <td>0.972338</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.574700</td>\n",
       "      <td>2.465089</td>\n",
       "      <td>0.602079</td>\n",
       "      <td>0.576725</td>\n",
       "      <td>0.755134</td>\n",
       "      <td>0.970240</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.472600</td>\n",
       "      <td>2.470450</td>\n",
       "      <td>0.619488</td>\n",
       "      <td>0.590695</td>\n",
       "      <td>0.771971</td>\n",
       "      <td>0.969141</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.755700</td>\n",
       "      <td>2.463162</td>\n",
       "      <td>0.655733</td>\n",
       "      <td>0.630758</td>\n",
       "      <td>0.798072</td>\n",
       "      <td>0.973263</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>3.207400</td>\n",
       "      <td>2.461634</td>\n",
       "      <td>0.678092</td>\n",
       "      <td>0.653969</td>\n",
       "      <td>0.812795</td>\n",
       "      <td>0.976137</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.781500</td>\n",
       "      <td>2.456028</td>\n",
       "      <td>0.642780</td>\n",
       "      <td>0.618189</td>\n",
       "      <td>0.795484</td>\n",
       "      <td>0.974578</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.875800</td>\n",
       "      <td>2.456509</td>\n",
       "      <td>0.633615</td>\n",
       "      <td>0.611956</td>\n",
       "      <td>0.780821</td>\n",
       "      <td>0.978749</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.663800</td>\n",
       "      <td>2.452363</td>\n",
       "      <td>0.647193</td>\n",
       "      <td>0.626708</td>\n",
       "      <td>0.794695</td>\n",
       "      <td>0.980494</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.651500</td>\n",
       "      <td>2.455637</td>\n",
       "      <td>0.650651</td>\n",
       "      <td>0.626844</td>\n",
       "      <td>0.793397</td>\n",
       "      <td>0.974578</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.629500</td>\n",
       "      <td>2.454643</td>\n",
       "      <td>0.666192</td>\n",
       "      <td>0.645930</td>\n",
       "      <td>0.813480</td>\n",
       "      <td>0.981208</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.901700</td>\n",
       "      <td>2.452471</td>\n",
       "      <td>0.624315</td>\n",
       "      <td>0.602187</td>\n",
       "      <td>0.775822</td>\n",
       "      <td>0.976708</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.720800</td>\n",
       "      <td>2.447457</td>\n",
       "      <td>0.630344</td>\n",
       "      <td>0.613352</td>\n",
       "      <td>0.773472</td>\n",
       "      <td>0.978530</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.839300</td>\n",
       "      <td>2.445569</td>\n",
       "      <td>0.626622</td>\n",
       "      <td>0.608664</td>\n",
       "      <td>0.773839</td>\n",
       "      <td>0.979429</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.454100</td>\n",
       "      <td>2.449041</td>\n",
       "      <td>0.640206</td>\n",
       "      <td>0.621968</td>\n",
       "      <td>0.779455</td>\n",
       "      <td>0.980631</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.720800</td>\n",
       "      <td>2.446311</td>\n",
       "      <td>0.677623</td>\n",
       "      <td>0.659383</td>\n",
       "      <td>0.814624</td>\n",
       "      <td>0.983249</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.525500</td>\n",
       "      <td>2.442216</td>\n",
       "      <td>0.685746</td>\n",
       "      <td>0.671520</td>\n",
       "      <td>0.813874</td>\n",
       "      <td>0.984973</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.795800</td>\n",
       "      <td>2.446613</td>\n",
       "      <td>0.681687</td>\n",
       "      <td>0.666310</td>\n",
       "      <td>0.808210</td>\n",
       "      <td>0.983723</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.524100</td>\n",
       "      <td>2.446350</td>\n",
       "      <td>0.667790</td>\n",
       "      <td>0.650006</td>\n",
       "      <td>0.810618</td>\n",
       "      <td>0.982911</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.867800</td>\n",
       "      <td>2.443523</td>\n",
       "      <td>0.659036</td>\n",
       "      <td>0.641332</td>\n",
       "      <td>0.794455</td>\n",
       "      <td>0.982100</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>2.857200</td>\n",
       "      <td>2.443159</td>\n",
       "      <td>0.660172</td>\n",
       "      <td>0.641130</td>\n",
       "      <td>0.794176</td>\n",
       "      <td>0.979718</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>2.796400</td>\n",
       "      <td>2.438499</td>\n",
       "      <td>0.658628</td>\n",
       "      <td>0.638525</td>\n",
       "      <td>0.788618</td>\n",
       "      <td>0.984266</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>2.722700</td>\n",
       "      <td>2.439913</td>\n",
       "      <td>0.644186</td>\n",
       "      <td>0.626998</td>\n",
       "      <td>0.790831</td>\n",
       "      <td>0.985991</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>2.788800</td>\n",
       "      <td>2.435956</td>\n",
       "      <td>0.667994</td>\n",
       "      <td>0.652666</td>\n",
       "      <td>0.812219</td>\n",
       "      <td>0.987220</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.853700</td>\n",
       "      <td>2.437016</td>\n",
       "      <td>0.630278</td>\n",
       "      <td>0.613805</td>\n",
       "      <td>0.790622</td>\n",
       "      <td>0.983524</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>2.854100</td>\n",
       "      <td>2.441662</td>\n",
       "      <td>0.639359</td>\n",
       "      <td>0.620651</td>\n",
       "      <td>0.787665</td>\n",
       "      <td>0.983977</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>2.885100</td>\n",
       "      <td>2.442815</td>\n",
       "      <td>0.656063</td>\n",
       "      <td>0.637677</td>\n",
       "      <td>0.798201</td>\n",
       "      <td>0.984774</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>3.095100</td>\n",
       "      <td>2.438004</td>\n",
       "      <td>0.630306</td>\n",
       "      <td>0.610615</td>\n",
       "      <td>0.771292</td>\n",
       "      <td>0.984246</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>2.740900</td>\n",
       "      <td>2.437559</td>\n",
       "      <td>0.642683</td>\n",
       "      <td>0.625659</td>\n",
       "      <td>0.780692</td>\n",
       "      <td>0.984075</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.622900</td>\n",
       "      <td>2.440077</td>\n",
       "      <td>0.659689</td>\n",
       "      <td>0.643447</td>\n",
       "      <td>0.793064</td>\n",
       "      <td>0.984795</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>2.702600</td>\n",
       "      <td>2.438575</td>\n",
       "      <td>0.664192</td>\n",
       "      <td>0.649042</td>\n",
       "      <td>0.793065</td>\n",
       "      <td>0.985674</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>2.731200</td>\n",
       "      <td>2.435075</td>\n",
       "      <td>0.654306</td>\n",
       "      <td>0.638127</td>\n",
       "      <td>0.783528</td>\n",
       "      <td>0.986752</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>2.457500</td>\n",
       "      <td>2.438529</td>\n",
       "      <td>0.655990</td>\n",
       "      <td>0.641781</td>\n",
       "      <td>0.784332</td>\n",
       "      <td>0.987525</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>2.918800</td>\n",
       "      <td>2.436454</td>\n",
       "      <td>0.648923</td>\n",
       "      <td>0.633074</td>\n",
       "      <td>0.777807</td>\n",
       "      <td>0.985408</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.721900</td>\n",
       "      <td>2.438118</td>\n",
       "      <td>0.635215</td>\n",
       "      <td>0.618533</td>\n",
       "      <td>0.766932</td>\n",
       "      <td>0.984259</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>2.630200</td>\n",
       "      <td>2.439244</td>\n",
       "      <td>0.638415</td>\n",
       "      <td>0.622853</td>\n",
       "      <td>0.769250</td>\n",
       "      <td>0.985269</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>2.807500</td>\n",
       "      <td>2.439879</td>\n",
       "      <td>0.657185</td>\n",
       "      <td>0.640913</td>\n",
       "      <td>0.777398</td>\n",
       "      <td>0.985269</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>2.524300</td>\n",
       "      <td>2.442605</td>\n",
       "      <td>0.646253</td>\n",
       "      <td>0.623794</td>\n",
       "      <td>0.785362</td>\n",
       "      <td>0.979011</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>2.588100</td>\n",
       "      <td>2.440284</td>\n",
       "      <td>0.645217</td>\n",
       "      <td>0.626523</td>\n",
       "      <td>0.777684</td>\n",
       "      <td>0.981097</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.905900</td>\n",
       "      <td>2.439944</td>\n",
       "      <td>0.646297</td>\n",
       "      <td>0.629057</td>\n",
       "      <td>0.771412</td>\n",
       "      <td>0.980116</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>2.725500</td>\n",
       "      <td>2.438508</td>\n",
       "      <td>0.654927</td>\n",
       "      <td>0.638169</td>\n",
       "      <td>0.777409</td>\n",
       "      <td>0.981759</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>2.719700</td>\n",
       "      <td>2.438921</td>\n",
       "      <td>0.679981</td>\n",
       "      <td>0.661177</td>\n",
       "      <td>0.793306</td>\n",
       "      <td>0.981525</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>2.770100</td>\n",
       "      <td>2.440337</td>\n",
       "      <td>0.658887</td>\n",
       "      <td>0.640573</td>\n",
       "      <td>0.784361</td>\n",
       "      <td>0.982535</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>2.767900</td>\n",
       "      <td>2.439549</td>\n",
       "      <td>0.645649</td>\n",
       "      <td>0.629024</td>\n",
       "      <td>0.774420</td>\n",
       "      <td>0.982674</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.529400</td>\n",
       "      <td>2.440349</td>\n",
       "      <td>0.672977</td>\n",
       "      <td>0.654419</td>\n",
       "      <td>0.787979</td>\n",
       "      <td>0.982239</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>2.913000</td>\n",
       "      <td>2.443464</td>\n",
       "      <td>0.678667</td>\n",
       "      <td>0.659399</td>\n",
       "      <td>0.802306</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>3.092700</td>\n",
       "      <td>2.438129</td>\n",
       "      <td>0.658486</td>\n",
       "      <td>0.641886</td>\n",
       "      <td>0.789608</td>\n",
       "      <td>0.981408</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>2.689600</td>\n",
       "      <td>2.437967</td>\n",
       "      <td>0.651886</td>\n",
       "      <td>0.636536</td>\n",
       "      <td>0.781619</td>\n",
       "      <td>0.984148</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>2.772500</td>\n",
       "      <td>2.438361</td>\n",
       "      <td>0.679532</td>\n",
       "      <td>0.660596</td>\n",
       "      <td>0.792570</td>\n",
       "      <td>0.984059</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>3.036100</td>\n",
       "      <td>2.437375</td>\n",
       "      <td>0.681532</td>\n",
       "      <td>0.662734</td>\n",
       "      <td>0.798836</td>\n",
       "      <td>0.984348</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>2.394800</td>\n",
       "      <td>2.435436</td>\n",
       "      <td>0.668574</td>\n",
       "      <td>0.650306</td>\n",
       "      <td>0.784496</td>\n",
       "      <td>0.987357</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>2.726800</td>\n",
       "      <td>2.439264</td>\n",
       "      <td>0.662731</td>\n",
       "      <td>0.643381</td>\n",
       "      <td>0.791024</td>\n",
       "      <td>0.984857</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>2.826200</td>\n",
       "      <td>2.440121</td>\n",
       "      <td>0.674473</td>\n",
       "      <td>0.656448</td>\n",
       "      <td>0.797278</td>\n",
       "      <td>0.989021</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>2.661900</td>\n",
       "      <td>2.437469</td>\n",
       "      <td>0.663922</td>\n",
       "      <td>0.646301</td>\n",
       "      <td>0.801368</td>\n",
       "      <td>0.989200</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.433600</td>\n",
       "      <td>2.437975</td>\n",
       "      <td>0.685197</td>\n",
       "      <td>0.667460</td>\n",
       "      <td>0.820367</td>\n",
       "      <td>0.986700</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>2.878300</td>\n",
       "      <td>2.437994</td>\n",
       "      <td>0.650466</td>\n",
       "      <td>0.631863</td>\n",
       "      <td>0.792235</td>\n",
       "      <td>0.984157</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>2.454400</td>\n",
       "      <td>2.434780</td>\n",
       "      <td>0.651145</td>\n",
       "      <td>0.634450</td>\n",
       "      <td>0.786304</td>\n",
       "      <td>0.984336</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>2.632000</td>\n",
       "      <td>2.433955</td>\n",
       "      <td>0.661357</td>\n",
       "      <td>0.645265</td>\n",
       "      <td>0.797636</td>\n",
       "      <td>0.985388</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>2.934400</td>\n",
       "      <td>2.435329</td>\n",
       "      <td>0.669489</td>\n",
       "      <td>0.653958</td>\n",
       "      <td>0.805241</td>\n",
       "      <td>0.987737</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.929300</td>\n",
       "      <td>2.438201</td>\n",
       "      <td>0.654488</td>\n",
       "      <td>0.637208</td>\n",
       "      <td>0.793527</td>\n",
       "      <td>0.982330</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>3.026500</td>\n",
       "      <td>2.434899</td>\n",
       "      <td>0.658401</td>\n",
       "      <td>0.642458</td>\n",
       "      <td>0.789620</td>\n",
       "      <td>0.986415</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>3.017100</td>\n",
       "      <td>2.435161</td>\n",
       "      <td>0.651490</td>\n",
       "      <td>0.633759</td>\n",
       "      <td>0.792760</td>\n",
       "      <td>0.986415</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>2.361600</td>\n",
       "      <td>2.429560</td>\n",
       "      <td>0.668740</td>\n",
       "      <td>0.655594</td>\n",
       "      <td>0.799403</td>\n",
       "      <td>0.988435</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>2.471100</td>\n",
       "      <td>2.430286</td>\n",
       "      <td>0.670095</td>\n",
       "      <td>0.654043</td>\n",
       "      <td>0.795604</td>\n",
       "      <td>0.985935</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.855900</td>\n",
       "      <td>2.430540</td>\n",
       "      <td>0.655238</td>\n",
       "      <td>0.642956</td>\n",
       "      <td>0.790166</td>\n",
       "      <td>0.990616</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>2.887000</td>\n",
       "      <td>2.433118</td>\n",
       "      <td>0.670930</td>\n",
       "      <td>0.655812</td>\n",
       "      <td>0.796803</td>\n",
       "      <td>0.987106</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940</td>\n",
       "      <td>2.638100</td>\n",
       "      <td>2.436227</td>\n",
       "      <td>0.653738</td>\n",
       "      <td>0.639847</td>\n",
       "      <td>0.788382</td>\n",
       "      <td>0.988575</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>2.662200</td>\n",
       "      <td>2.435852</td>\n",
       "      <td>0.644346</td>\n",
       "      <td>0.627922</td>\n",
       "      <td>0.788278</td>\n",
       "      <td>0.986500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>2.471200</td>\n",
       "      <td>2.436370</td>\n",
       "      <td>0.649960</td>\n",
       "      <td>0.633103</td>\n",
       "      <td>0.786436</td>\n",
       "      <td>0.989606</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.434300</td>\n",
       "      <td>2.434274</td>\n",
       "      <td>0.640641</td>\n",
       "      <td>0.625059</td>\n",
       "      <td>0.774445</td>\n",
       "      <td>0.988267</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>2.484500</td>\n",
       "      <td>2.437764</td>\n",
       "      <td>0.673271</td>\n",
       "      <td>0.654411</td>\n",
       "      <td>0.794082</td>\n",
       "      <td>0.984927</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>2.762800</td>\n",
       "      <td>2.434164</td>\n",
       "      <td>0.642617</td>\n",
       "      <td>0.626649</td>\n",
       "      <td>0.784593</td>\n",
       "      <td>0.988526</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2060</td>\n",
       "      <td>2.891200</td>\n",
       "      <td>2.435319</td>\n",
       "      <td>0.657505</td>\n",
       "      <td>0.642477</td>\n",
       "      <td>0.783728</td>\n",
       "      <td>0.987495</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2080</td>\n",
       "      <td>2.521200</td>\n",
       "      <td>2.432760</td>\n",
       "      <td>0.647506</td>\n",
       "      <td>0.632425</td>\n",
       "      <td>0.773912</td>\n",
       "      <td>0.987565</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.732800</td>\n",
       "      <td>2.434567</td>\n",
       "      <td>0.663744</td>\n",
       "      <td>0.649113</td>\n",
       "      <td>0.781350</td>\n",
       "      <td>0.991647</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2120</td>\n",
       "      <td>2.868700</td>\n",
       "      <td>2.435935</td>\n",
       "      <td>0.666220</td>\n",
       "      <td>0.649153</td>\n",
       "      <td>0.786775</td>\n",
       "      <td>0.989199</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>2.952300</td>\n",
       "      <td>2.434085</td>\n",
       "      <td>0.649385</td>\n",
       "      <td>0.633897</td>\n",
       "      <td>0.769025</td>\n",
       "      <td>0.990348</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>2.888800</td>\n",
       "      <td>2.435872</td>\n",
       "      <td>0.648018</td>\n",
       "      <td>0.632771</td>\n",
       "      <td>0.775587</td>\n",
       "      <td>0.989874</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2180</td>\n",
       "      <td>2.698800</td>\n",
       "      <td>2.432964</td>\n",
       "      <td>0.650752</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.772975</td>\n",
       "      <td>0.988307</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.671100</td>\n",
       "      <td>2.434028</td>\n",
       "      <td>0.647158</td>\n",
       "      <td>0.630538</td>\n",
       "      <td>0.788412</td>\n",
       "      <td>0.989626</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>2.807000</td>\n",
       "      <td>2.438078</td>\n",
       "      <td>0.665168</td>\n",
       "      <td>0.647065</td>\n",
       "      <td>0.791126</td>\n",
       "      <td>0.990052</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>2.593100</td>\n",
       "      <td>2.445889</td>\n",
       "      <td>0.666967</td>\n",
       "      <td>0.646709</td>\n",
       "      <td>0.794293</td>\n",
       "      <td>0.986890</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2260</td>\n",
       "      <td>2.652900</td>\n",
       "      <td>2.437073</td>\n",
       "      <td>0.654742</td>\n",
       "      <td>0.636877</td>\n",
       "      <td>0.776428</td>\n",
       "      <td>0.988753</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>2.769900</td>\n",
       "      <td>2.437747</td>\n",
       "      <td>0.651290</td>\n",
       "      <td>0.630965</td>\n",
       "      <td>0.775068</td>\n",
       "      <td>0.988596</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>2.774000</td>\n",
       "      <td>2.434418</td>\n",
       "      <td>0.699991</td>\n",
       "      <td>0.684427</td>\n",
       "      <td>0.802803</td>\n",
       "      <td>0.988456</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2320</td>\n",
       "      <td>2.790700</td>\n",
       "      <td>2.434777</td>\n",
       "      <td>0.651588</td>\n",
       "      <td>0.634534</td>\n",
       "      <td>0.783315</td>\n",
       "      <td>0.987158</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>2.758000</td>\n",
       "      <td>2.432832</td>\n",
       "      <td>0.648788</td>\n",
       "      <td>0.633556</td>\n",
       "      <td>0.778172</td>\n",
       "      <td>0.987158</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2360</td>\n",
       "      <td>2.659800</td>\n",
       "      <td>2.429149</td>\n",
       "      <td>0.667770</td>\n",
       "      <td>0.652201</td>\n",
       "      <td>0.780462</td>\n",
       "      <td>0.986966</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2380</td>\n",
       "      <td>2.881800</td>\n",
       "      <td>2.429245</td>\n",
       "      <td>0.659686</td>\n",
       "      <td>0.642296</td>\n",
       "      <td>0.788167</td>\n",
       "      <td>0.986273</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.912500</td>\n",
       "      <td>2.429651</td>\n",
       "      <td>0.653730</td>\n",
       "      <td>0.636893</td>\n",
       "      <td>0.775449</td>\n",
       "      <td>0.986987</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2420</td>\n",
       "      <td>2.519200</td>\n",
       "      <td>2.427100</td>\n",
       "      <td>0.652737</td>\n",
       "      <td>0.637373</td>\n",
       "      <td>0.771154</td>\n",
       "      <td>0.987742</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2440</td>\n",
       "      <td>2.682800</td>\n",
       "      <td>2.428318</td>\n",
       "      <td>0.663241</td>\n",
       "      <td>0.648472</td>\n",
       "      <td>0.774614</td>\n",
       "      <td>0.987693</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>2.553000</td>\n",
       "      <td>2.425149</td>\n",
       "      <td>0.683037</td>\n",
       "      <td>0.668014</td>\n",
       "      <td>0.797564</td>\n",
       "      <td>0.987848</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2480</td>\n",
       "      <td>2.760200</td>\n",
       "      <td>2.427022</td>\n",
       "      <td>0.667826</td>\n",
       "      <td>0.654013</td>\n",
       "      <td>0.785839</td>\n",
       "      <td>0.988624</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.705600</td>\n",
       "      <td>2.429211</td>\n",
       "      <td>0.664406</td>\n",
       "      <td>0.650779</td>\n",
       "      <td>0.779619</td>\n",
       "      <td>0.991647</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>2.598000</td>\n",
       "      <td>2.426804</td>\n",
       "      <td>0.688461</td>\n",
       "      <td>0.675020</td>\n",
       "      <td>0.803980</td>\n",
       "      <td>0.991647</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540</td>\n",
       "      <td>2.658200</td>\n",
       "      <td>2.427764</td>\n",
       "      <td>0.684736</td>\n",
       "      <td>0.672731</td>\n",
       "      <td>0.797298</td>\n",
       "      <td>0.994621</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>2.758500</td>\n",
       "      <td>2.427838</td>\n",
       "      <td>0.694083</td>\n",
       "      <td>0.678891</td>\n",
       "      <td>0.810805</td>\n",
       "      <td>0.990616</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>2.730800</td>\n",
       "      <td>2.427890</td>\n",
       "      <td>0.665090</td>\n",
       "      <td>0.651214</td>\n",
       "      <td>0.779190</td>\n",
       "      <td>0.991747</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.715700</td>\n",
       "      <td>2.428676</td>\n",
       "      <td>0.662926</td>\n",
       "      <td>0.649191</td>\n",
       "      <td>0.777443</td>\n",
       "      <td>0.992897</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2620</td>\n",
       "      <td>2.417100</td>\n",
       "      <td>2.428646</td>\n",
       "      <td>0.665990</td>\n",
       "      <td>0.651512</td>\n",
       "      <td>0.780738</td>\n",
       "      <td>0.992897</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>2.789600</td>\n",
       "      <td>2.427462</td>\n",
       "      <td>0.663808</td>\n",
       "      <td>0.649260</td>\n",
       "      <td>0.779181</td>\n",
       "      <td>0.990616</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2660</td>\n",
       "      <td>3.253300</td>\n",
       "      <td>2.427773</td>\n",
       "      <td>0.690364</td>\n",
       "      <td>0.676845</td>\n",
       "      <td>0.803932</td>\n",
       "      <td>0.992897</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2680</td>\n",
       "      <td>2.601900</td>\n",
       "      <td>2.428729</td>\n",
       "      <td>0.660077</td>\n",
       "      <td>0.648135</td>\n",
       "      <td>0.780259</td>\n",
       "      <td>0.991647</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>2.925000</td>\n",
       "      <td>2.427215</td>\n",
       "      <td>0.671276</td>\n",
       "      <td>0.659238</td>\n",
       "      <td>0.773522</td>\n",
       "      <td>0.991647</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2720</td>\n",
       "      <td>2.391700</td>\n",
       "      <td>2.426760</td>\n",
       "      <td>0.666767</td>\n",
       "      <td>0.655243</td>\n",
       "      <td>0.776247</td>\n",
       "      <td>0.992072</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2740</td>\n",
       "      <td>2.857000</td>\n",
       "      <td>2.430563</td>\n",
       "      <td>0.656332</td>\n",
       "      <td>0.642280</td>\n",
       "      <td>0.771890</td>\n",
       "      <td>0.990348</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2760</td>\n",
       "      <td>2.764300</td>\n",
       "      <td>2.428854</td>\n",
       "      <td>0.645899</td>\n",
       "      <td>0.629979</td>\n",
       "      <td>0.760233</td>\n",
       "      <td>0.986124</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2780</td>\n",
       "      <td>2.818200</td>\n",
       "      <td>2.427442</td>\n",
       "      <td>0.652884</td>\n",
       "      <td>0.637683</td>\n",
       "      <td>0.767598</td>\n",
       "      <td>0.987423</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>2.717300</td>\n",
       "      <td>2.430163</td>\n",
       "      <td>0.656092</td>\n",
       "      <td>0.639751</td>\n",
       "      <td>0.764587</td>\n",
       "      <td>0.989466</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2820</td>\n",
       "      <td>2.711200</td>\n",
       "      <td>2.427752</td>\n",
       "      <td>0.666697</td>\n",
       "      <td>0.651150</td>\n",
       "      <td>0.776960</td>\n",
       "      <td>0.989721</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2840</td>\n",
       "      <td>2.916900</td>\n",
       "      <td>2.426312</td>\n",
       "      <td>0.691365</td>\n",
       "      <td>0.678047</td>\n",
       "      <td>0.787592</td>\n",
       "      <td>0.991330</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2860</td>\n",
       "      <td>2.841800</td>\n",
       "      <td>2.427657</td>\n",
       "      <td>0.662106</td>\n",
       "      <td>0.648245</td>\n",
       "      <td>0.764233</td>\n",
       "      <td>0.992289</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>2.691100</td>\n",
       "      <td>2.427104</td>\n",
       "      <td>0.684448</td>\n",
       "      <td>0.670258</td>\n",
       "      <td>0.775177</td>\n",
       "      <td>0.989466</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>2.554800</td>\n",
       "      <td>2.429101</td>\n",
       "      <td>0.661990</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.779050</td>\n",
       "      <td>0.987742</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2920</td>\n",
       "      <td>2.803500</td>\n",
       "      <td>2.429203</td>\n",
       "      <td>0.669107</td>\n",
       "      <td>0.653815</td>\n",
       "      <td>0.764976</td>\n",
       "      <td>0.990160</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2940</td>\n",
       "      <td>2.897200</td>\n",
       "      <td>2.432315</td>\n",
       "      <td>0.664519</td>\n",
       "      <td>0.646734</td>\n",
       "      <td>0.775252</td>\n",
       "      <td>0.988435</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2960</td>\n",
       "      <td>2.689300</td>\n",
       "      <td>2.429195</td>\n",
       "      <td>0.656145</td>\n",
       "      <td>0.639184</td>\n",
       "      <td>0.762170</td>\n",
       "      <td>0.988435</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2980</td>\n",
       "      <td>2.853000</td>\n",
       "      <td>2.427499</td>\n",
       "      <td>0.661229</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.769712</td>\n",
       "      <td>0.988335</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.543300</td>\n",
       "      <td>2.427631</td>\n",
       "      <td>0.655702</td>\n",
       "      <td>0.642489</td>\n",
       "      <td>0.767198</td>\n",
       "      <td>0.990160</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3020</td>\n",
       "      <td>2.790100</td>\n",
       "      <td>2.429481</td>\n",
       "      <td>0.665907</td>\n",
       "      <td>0.651518</td>\n",
       "      <td>0.768808</td>\n",
       "      <td>0.990160</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3040</td>\n",
       "      <td>2.898100</td>\n",
       "      <td>2.430592</td>\n",
       "      <td>0.679399</td>\n",
       "      <td>0.666495</td>\n",
       "      <td>0.776868</td>\n",
       "      <td>0.991190</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3060</td>\n",
       "      <td>2.483500</td>\n",
       "      <td>2.428462</td>\n",
       "      <td>0.669595</td>\n",
       "      <td>0.655254</td>\n",
       "      <td>0.773761</td>\n",
       "      <td>0.987879</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3080</td>\n",
       "      <td>2.499400</td>\n",
       "      <td>2.427011</td>\n",
       "      <td>0.684392</td>\n",
       "      <td>0.669259</td>\n",
       "      <td>0.776907</td>\n",
       "      <td>0.992440</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>2.512900</td>\n",
       "      <td>2.429687</td>\n",
       "      <td>0.675109</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>0.779159</td>\n",
       "      <td>0.988910</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3120</td>\n",
       "      <td>2.646600</td>\n",
       "      <td>2.429536</td>\n",
       "      <td>0.687340</td>\n",
       "      <td>0.673571</td>\n",
       "      <td>0.786782</td>\n",
       "      <td>0.990160</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3140</td>\n",
       "      <td>2.720600</td>\n",
       "      <td>2.431631</td>\n",
       "      <td>0.675701</td>\n",
       "      <td>0.661325</td>\n",
       "      <td>0.780942</td>\n",
       "      <td>0.988861</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3160</td>\n",
       "      <td>2.634600</td>\n",
       "      <td>2.430488</td>\n",
       "      <td>0.697206</td>\n",
       "      <td>0.682221</td>\n",
       "      <td>0.782806</td>\n",
       "      <td>0.988423</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3180</td>\n",
       "      <td>2.757400</td>\n",
       "      <td>2.432069</td>\n",
       "      <td>0.667795</td>\n",
       "      <td>0.655043</td>\n",
       "      <td>0.768211</td>\n",
       "      <td>0.992072</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>2.695200</td>\n",
       "      <td>2.434386</td>\n",
       "      <td>0.687733</td>\n",
       "      <td>0.673269</td>\n",
       "      <td>0.776074</td>\n",
       "      <td>0.990923</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3220</td>\n",
       "      <td>2.453000</td>\n",
       "      <td>2.432773</td>\n",
       "      <td>0.686765</td>\n",
       "      <td>0.672347</td>\n",
       "      <td>0.779559</td>\n",
       "      <td>0.990923</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3240</td>\n",
       "      <td>2.719700</td>\n",
       "      <td>2.431691</td>\n",
       "      <td>0.686242</td>\n",
       "      <td>0.672210</td>\n",
       "      <td>0.782533</td>\n",
       "      <td>0.993322</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3260</td>\n",
       "      <td>3.096200</td>\n",
       "      <td>2.430411</td>\n",
       "      <td>0.681246</td>\n",
       "      <td>0.666202</td>\n",
       "      <td>0.779353</td>\n",
       "      <td>0.990871</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3280</td>\n",
       "      <td>2.623400</td>\n",
       "      <td>2.430397</td>\n",
       "      <td>0.682386</td>\n",
       "      <td>0.667690</td>\n",
       "      <td>0.777319</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>2.470100</td>\n",
       "      <td>2.430537</td>\n",
       "      <td>0.678561</td>\n",
       "      <td>0.663093</td>\n",
       "      <td>0.779091</td>\n",
       "      <td>0.991041</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3320</td>\n",
       "      <td>2.655400</td>\n",
       "      <td>2.429947</td>\n",
       "      <td>0.693211</td>\n",
       "      <td>0.678141</td>\n",
       "      <td>0.776811</td>\n",
       "      <td>0.992072</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3340</td>\n",
       "      <td>2.611000</td>\n",
       "      <td>2.427633</td>\n",
       "      <td>0.668081</td>\n",
       "      <td>0.652500</td>\n",
       "      <td>0.764950</td>\n",
       "      <td>0.989572</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3360</td>\n",
       "      <td>2.865500</td>\n",
       "      <td>2.425825</td>\n",
       "      <td>0.674461</td>\n",
       "      <td>0.660670</td>\n",
       "      <td>0.765880</td>\n",
       "      <td>0.992072</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3380</td>\n",
       "      <td>2.326000</td>\n",
       "      <td>2.427116</td>\n",
       "      <td>0.675577</td>\n",
       "      <td>0.660114</td>\n",
       "      <td>0.765900</td>\n",
       "      <td>0.991041</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>2.647300</td>\n",
       "      <td>2.427067</td>\n",
       "      <td>0.659552</td>\n",
       "      <td>0.645746</td>\n",
       "      <td>0.758099</td>\n",
       "      <td>0.993371</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3420</td>\n",
       "      <td>2.533300</td>\n",
       "      <td>2.426458</td>\n",
       "      <td>0.656739</td>\n",
       "      <td>0.643052</td>\n",
       "      <td>0.760846</td>\n",
       "      <td>0.991647</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3440</td>\n",
       "      <td>2.561600</td>\n",
       "      <td>2.425994</td>\n",
       "      <td>0.667513</td>\n",
       "      <td>0.652912</td>\n",
       "      <td>0.767661</td>\n",
       "      <td>0.989366</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3460</td>\n",
       "      <td>2.647100</td>\n",
       "      <td>2.427318</td>\n",
       "      <td>0.661091</td>\n",
       "      <td>0.647457</td>\n",
       "      <td>0.766126</td>\n",
       "      <td>0.991866</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3480</td>\n",
       "      <td>2.782300</td>\n",
       "      <td>2.428316</td>\n",
       "      <td>0.674362</td>\n",
       "      <td>0.658829</td>\n",
       "      <td>0.769042</td>\n",
       "      <td>0.989840</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.725800</td>\n",
       "      <td>2.428734</td>\n",
       "      <td>0.666200</td>\n",
       "      <td>0.652508</td>\n",
       "      <td>0.768131</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3520</td>\n",
       "      <td>2.816600</td>\n",
       "      <td>2.429790</td>\n",
       "      <td>0.686806</td>\n",
       "      <td>0.673279</td>\n",
       "      <td>0.779296</td>\n",
       "      <td>0.993590</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3540</td>\n",
       "      <td>2.757000</td>\n",
       "      <td>2.429502</td>\n",
       "      <td>0.687737</td>\n",
       "      <td>0.673516</td>\n",
       "      <td>0.776958</td>\n",
       "      <td>0.992121</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3560</td>\n",
       "      <td>2.553000</td>\n",
       "      <td>2.430572</td>\n",
       "      <td>0.675580</td>\n",
       "      <td>0.661694</td>\n",
       "      <td>0.768278</td>\n",
       "      <td>0.993471</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3580</td>\n",
       "      <td>2.638000</td>\n",
       "      <td>2.431509</td>\n",
       "      <td>0.679556</td>\n",
       "      <td>0.664738</td>\n",
       "      <td>0.769228</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>2.608100</td>\n",
       "      <td>2.431288</td>\n",
       "      <td>0.671631</td>\n",
       "      <td>0.657488</td>\n",
       "      <td>0.768863</td>\n",
       "      <td>0.990923</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3620</td>\n",
       "      <td>2.731000</td>\n",
       "      <td>2.431954</td>\n",
       "      <td>0.698341</td>\n",
       "      <td>0.683786</td>\n",
       "      <td>0.780642</td>\n",
       "      <td>0.989673</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3640</td>\n",
       "      <td>2.472900</td>\n",
       "      <td>2.432052</td>\n",
       "      <td>0.669012</td>\n",
       "      <td>0.654966</td>\n",
       "      <td>0.771542</td>\n",
       "      <td>0.989673</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3660</td>\n",
       "      <td>2.961100</td>\n",
       "      <td>2.432714</td>\n",
       "      <td>0.690987</td>\n",
       "      <td>0.676474</td>\n",
       "      <td>0.783449</td>\n",
       "      <td>0.990923</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3680</td>\n",
       "      <td>2.698700</td>\n",
       "      <td>2.433026</td>\n",
       "      <td>0.685632</td>\n",
       "      <td>0.671170</td>\n",
       "      <td>0.775397</td>\n",
       "      <td>0.990923</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>2.791500</td>\n",
       "      <td>2.433229</td>\n",
       "      <td>0.684917</td>\n",
       "      <td>0.669147</td>\n",
       "      <td>0.772059</td>\n",
       "      <td>0.989199</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3720</td>\n",
       "      <td>2.803300</td>\n",
       "      <td>2.431463</td>\n",
       "      <td>0.684902</td>\n",
       "      <td>0.668175</td>\n",
       "      <td>0.770165</td>\n",
       "      <td>0.986699</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3740</td>\n",
       "      <td>2.774500</td>\n",
       "      <td>2.427365</td>\n",
       "      <td>0.688881</td>\n",
       "      <td>0.673834</td>\n",
       "      <td>0.777763</td>\n",
       "      <td>0.989721</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3760</td>\n",
       "      <td>2.804900</td>\n",
       "      <td>2.427117</td>\n",
       "      <td>0.663724</td>\n",
       "      <td>0.650185</td>\n",
       "      <td>0.770392</td>\n",
       "      <td>0.990971</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3780</td>\n",
       "      <td>2.756600</td>\n",
       "      <td>2.427030</td>\n",
       "      <td>0.686719</td>\n",
       "      <td>0.671753</td>\n",
       "      <td>0.774237</td>\n",
       "      <td>0.989721</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>2.706600</td>\n",
       "      <td>2.427538</td>\n",
       "      <td>0.686718</td>\n",
       "      <td>0.672694</td>\n",
       "      <td>0.768971</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3820</td>\n",
       "      <td>2.789800</td>\n",
       "      <td>2.428756</td>\n",
       "      <td>0.697592</td>\n",
       "      <td>0.683535</td>\n",
       "      <td>0.773705</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3840</td>\n",
       "      <td>2.770200</td>\n",
       "      <td>2.428187</td>\n",
       "      <td>0.680662</td>\n",
       "      <td>0.666751</td>\n",
       "      <td>0.769050</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3860</td>\n",
       "      <td>2.465100</td>\n",
       "      <td>2.430293</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.675024</td>\n",
       "      <td>0.779456</td>\n",
       "      <td>0.989721</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3880</td>\n",
       "      <td>2.795400</td>\n",
       "      <td>2.428486</td>\n",
       "      <td>0.677947</td>\n",
       "      <td>0.663979</td>\n",
       "      <td>0.768524</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>2.763900</td>\n",
       "      <td>2.427725</td>\n",
       "      <td>0.684262</td>\n",
       "      <td>0.669926</td>\n",
       "      <td>0.771421</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3920</td>\n",
       "      <td>2.559100</td>\n",
       "      <td>2.426833</td>\n",
       "      <td>0.682831</td>\n",
       "      <td>0.670022</td>\n",
       "      <td>0.772228</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3940</td>\n",
       "      <td>2.476500</td>\n",
       "      <td>2.426009</td>\n",
       "      <td>0.689784</td>\n",
       "      <td>0.676829</td>\n",
       "      <td>0.778974</td>\n",
       "      <td>0.990971</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3960</td>\n",
       "      <td>2.656200</td>\n",
       "      <td>2.426936</td>\n",
       "      <td>0.689226</td>\n",
       "      <td>0.676283</td>\n",
       "      <td>0.778586</td>\n",
       "      <td>0.990971</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3980</td>\n",
       "      <td>2.855500</td>\n",
       "      <td>2.427007</td>\n",
       "      <td>0.694540</td>\n",
       "      <td>0.681485</td>\n",
       "      <td>0.784676</td>\n",
       "      <td>0.990971</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.848100</td>\n",
       "      <td>2.426637</td>\n",
       "      <td>0.675896</td>\n",
       "      <td>0.663233</td>\n",
       "      <td>0.774801</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4020</td>\n",
       "      <td>2.740700</td>\n",
       "      <td>2.428318</td>\n",
       "      <td>0.688881</td>\n",
       "      <td>0.674494</td>\n",
       "      <td>0.774233</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4040</td>\n",
       "      <td>2.594400</td>\n",
       "      <td>2.428775</td>\n",
       "      <td>0.692130</td>\n",
       "      <td>0.679097</td>\n",
       "      <td>0.773660</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4060</td>\n",
       "      <td>2.604300</td>\n",
       "      <td>2.429972</td>\n",
       "      <td>0.686731</td>\n",
       "      <td>0.673769</td>\n",
       "      <td>0.774056</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4080</td>\n",
       "      <td>2.619700</td>\n",
       "      <td>2.429308</td>\n",
       "      <td>0.681592</td>\n",
       "      <td>0.669607</td>\n",
       "      <td>0.774353</td>\n",
       "      <td>0.993471</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>3.050800</td>\n",
       "      <td>2.429454</td>\n",
       "      <td>0.683017</td>\n",
       "      <td>0.669976</td>\n",
       "      <td>0.777149</td>\n",
       "      <td>0.993471</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4120</td>\n",
       "      <td>2.600300</td>\n",
       "      <td>2.431056</td>\n",
       "      <td>0.675292</td>\n",
       "      <td>0.661594</td>\n",
       "      <td>0.770632</td>\n",
       "      <td>0.990971</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4140</td>\n",
       "      <td>2.418600</td>\n",
       "      <td>2.431074</td>\n",
       "      <td>0.681644</td>\n",
       "      <td>0.667862</td>\n",
       "      <td>0.771833</td>\n",
       "      <td>0.992173</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4160</td>\n",
       "      <td>2.637400</td>\n",
       "      <td>2.430723</td>\n",
       "      <td>0.691565</td>\n",
       "      <td>0.676709</td>\n",
       "      <td>0.784685</td>\n",
       "      <td>0.990923</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4180</td>\n",
       "      <td>2.722000</td>\n",
       "      <td>2.430453</td>\n",
       "      <td>0.683576</td>\n",
       "      <td>0.668831</td>\n",
       "      <td>0.777056</td>\n",
       "      <td>0.990923</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>2.982500</td>\n",
       "      <td>2.430706</td>\n",
       "      <td>0.666290</td>\n",
       "      <td>0.651363</td>\n",
       "      <td>0.763336</td>\n",
       "      <td>0.989892</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4220</td>\n",
       "      <td>2.615700</td>\n",
       "      <td>2.431453</td>\n",
       "      <td>0.683681</td>\n",
       "      <td>0.668277</td>\n",
       "      <td>0.770842</td>\n",
       "      <td>0.989892</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4240</td>\n",
       "      <td>2.862900</td>\n",
       "      <td>2.433414</td>\n",
       "      <td>0.684425</td>\n",
       "      <td>0.669457</td>\n",
       "      <td>0.774684</td>\n",
       "      <td>0.989721</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4260</td>\n",
       "      <td>2.894000</td>\n",
       "      <td>2.432497</td>\n",
       "      <td>0.678872</td>\n",
       "      <td>0.664061</td>\n",
       "      <td>0.768415</td>\n",
       "      <td>0.989721</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4280</td>\n",
       "      <td>2.993200</td>\n",
       "      <td>2.432476</td>\n",
       "      <td>0.685998</td>\n",
       "      <td>0.672154</td>\n",
       "      <td>0.774885</td>\n",
       "      <td>0.989721</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>2.835700</td>\n",
       "      <td>2.432770</td>\n",
       "      <td>0.676665</td>\n",
       "      <td>0.663260</td>\n",
       "      <td>0.770814</td>\n",
       "      <td>0.989721</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4320</td>\n",
       "      <td>2.703200</td>\n",
       "      <td>2.430892</td>\n",
       "      <td>0.680435</td>\n",
       "      <td>0.666569</td>\n",
       "      <td>0.771068</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4340</td>\n",
       "      <td>2.790700</td>\n",
       "      <td>2.431427</td>\n",
       "      <td>0.684061</td>\n",
       "      <td>0.670051</td>\n",
       "      <td>0.771229</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4360</td>\n",
       "      <td>2.905100</td>\n",
       "      <td>2.432134</td>\n",
       "      <td>0.687377</td>\n",
       "      <td>0.672332</td>\n",
       "      <td>0.777774</td>\n",
       "      <td>0.989721</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4380</td>\n",
       "      <td>2.838600</td>\n",
       "      <td>2.431417</td>\n",
       "      <td>0.684888</td>\n",
       "      <td>0.670815</td>\n",
       "      <td>0.777030</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>2.723500</td>\n",
       "      <td>2.431175</td>\n",
       "      <td>0.687327</td>\n",
       "      <td>0.674428</td>\n",
       "      <td>0.775853</td>\n",
       "      <td>0.990923</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4420</td>\n",
       "      <td>2.532600</td>\n",
       "      <td>2.429061</td>\n",
       "      <td>0.681725</td>\n",
       "      <td>0.667333</td>\n",
       "      <td>0.772913</td>\n",
       "      <td>0.988423</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>2.629700</td>\n",
       "      <td>2.429521</td>\n",
       "      <td>0.680451</td>\n",
       "      <td>0.666083</td>\n",
       "      <td>0.771108</td>\n",
       "      <td>0.988423</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4460</td>\n",
       "      <td>2.438700</td>\n",
       "      <td>2.428553</td>\n",
       "      <td>0.685771</td>\n",
       "      <td>0.672984</td>\n",
       "      <td>0.778329</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4480</td>\n",
       "      <td>2.301500</td>\n",
       "      <td>2.427380</td>\n",
       "      <td>0.689771</td>\n",
       "      <td>0.677736</td>\n",
       "      <td>0.781409</td>\n",
       "      <td>0.993471</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>2.584900</td>\n",
       "      <td>2.428854</td>\n",
       "      <td>0.681996</td>\n",
       "      <td>0.669266</td>\n",
       "      <td>0.772430</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4520</td>\n",
       "      <td>2.930800</td>\n",
       "      <td>2.429074</td>\n",
       "      <td>0.688170</td>\n",
       "      <td>0.676651</td>\n",
       "      <td>0.783563</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4540</td>\n",
       "      <td>3.023400</td>\n",
       "      <td>2.429834</td>\n",
       "      <td>0.687042</td>\n",
       "      <td>0.675564</td>\n",
       "      <td>0.781579</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4560</td>\n",
       "      <td>2.657000</td>\n",
       "      <td>2.430090</td>\n",
       "      <td>0.683244</td>\n",
       "      <td>0.669773</td>\n",
       "      <td>0.771437</td>\n",
       "      <td>0.990923</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4580</td>\n",
       "      <td>2.663900</td>\n",
       "      <td>2.430279</td>\n",
       "      <td>0.684622</td>\n",
       "      <td>0.671085</td>\n",
       "      <td>0.775760</td>\n",
       "      <td>0.990923</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>2.337100</td>\n",
       "      <td>2.431108</td>\n",
       "      <td>0.687333</td>\n",
       "      <td>0.673502</td>\n",
       "      <td>0.775052</td>\n",
       "      <td>0.989721</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4620</td>\n",
       "      <td>2.525200</td>\n",
       "      <td>2.430562</td>\n",
       "      <td>0.689462</td>\n",
       "      <td>0.675567</td>\n",
       "      <td>0.781009</td>\n",
       "      <td>0.989721</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4640</td>\n",
       "      <td>2.561000</td>\n",
       "      <td>2.430348</td>\n",
       "      <td>0.684146</td>\n",
       "      <td>0.671408</td>\n",
       "      <td>0.777389</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4660</td>\n",
       "      <td>2.986500</td>\n",
       "      <td>2.430545</td>\n",
       "      <td>0.685472</td>\n",
       "      <td>0.672677</td>\n",
       "      <td>0.773576</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4680</td>\n",
       "      <td>2.836800</td>\n",
       "      <td>2.429860</td>\n",
       "      <td>0.680974</td>\n",
       "      <td>0.667592</td>\n",
       "      <td>0.771806</td>\n",
       "      <td>0.990923</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>2.575700</td>\n",
       "      <td>2.430818</td>\n",
       "      <td>0.685314</td>\n",
       "      <td>0.671715</td>\n",
       "      <td>0.776941</td>\n",
       "      <td>0.990923</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4720</td>\n",
       "      <td>2.829500</td>\n",
       "      <td>2.430114</td>\n",
       "      <td>0.689166</td>\n",
       "      <td>0.674531</td>\n",
       "      <td>0.781473</td>\n",
       "      <td>0.988423</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4740</td>\n",
       "      <td>2.465600</td>\n",
       "      <td>2.429919</td>\n",
       "      <td>0.685136</td>\n",
       "      <td>0.671600</td>\n",
       "      <td>0.774358</td>\n",
       "      <td>0.990923</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4760</td>\n",
       "      <td>2.977300</td>\n",
       "      <td>2.430514</td>\n",
       "      <td>0.688433</td>\n",
       "      <td>0.674881</td>\n",
       "      <td>0.776307</td>\n",
       "      <td>0.990923</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4780</td>\n",
       "      <td>2.748900</td>\n",
       "      <td>2.430065</td>\n",
       "      <td>0.688981</td>\n",
       "      <td>0.675313</td>\n",
       "      <td>0.776941</td>\n",
       "      <td>0.990923</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>3.168400</td>\n",
       "      <td>2.430413</td>\n",
       "      <td>0.691215</td>\n",
       "      <td>0.678276</td>\n",
       "      <td>0.779286</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4820</td>\n",
       "      <td>2.950500</td>\n",
       "      <td>2.430079</td>\n",
       "      <td>0.691255</td>\n",
       "      <td>0.678263</td>\n",
       "      <td>0.781743</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4840</td>\n",
       "      <td>2.525000</td>\n",
       "      <td>2.429690</td>\n",
       "      <td>0.692776</td>\n",
       "      <td>0.679767</td>\n",
       "      <td>0.780739</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4860</td>\n",
       "      <td>2.724800</td>\n",
       "      <td>2.430487</td>\n",
       "      <td>0.686607</td>\n",
       "      <td>0.673817</td>\n",
       "      <td>0.774193</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4880</td>\n",
       "      <td>2.610100</td>\n",
       "      <td>2.429996</td>\n",
       "      <td>0.689076</td>\n",
       "      <td>0.676206</td>\n",
       "      <td>0.777458</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>2.368900</td>\n",
       "      <td>2.430004</td>\n",
       "      <td>0.692553</td>\n",
       "      <td>0.679600</td>\n",
       "      <td>0.783572</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4920</td>\n",
       "      <td>2.558300</td>\n",
       "      <td>2.430407</td>\n",
       "      <td>0.694092</td>\n",
       "      <td>0.681136</td>\n",
       "      <td>0.780356</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4940</td>\n",
       "      <td>2.610200</td>\n",
       "      <td>2.430973</td>\n",
       "      <td>0.686607</td>\n",
       "      <td>0.673795</td>\n",
       "      <td>0.775857</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4960</td>\n",
       "      <td>2.462900</td>\n",
       "      <td>2.430525</td>\n",
       "      <td>0.686943</td>\n",
       "      <td>0.674088</td>\n",
       "      <td>0.774951</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4980</td>\n",
       "      <td>2.611000</td>\n",
       "      <td>2.430727</td>\n",
       "      <td>0.686215</td>\n",
       "      <td>0.673485</td>\n",
       "      <td>0.772646</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.566600</td>\n",
       "      <td>2.430738</td>\n",
       "      <td>0.691009</td>\n",
       "      <td>0.678180</td>\n",
       "      <td>0.777620</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❌ [OOM at step 301] Skipping this batch.\n",
      "    input_ids shape: torch.Size([2, 636])\n",
      "    labels shape: torch.Size([2, 636])\n",
      "💾 Saving checkpoint due to OOM at: ./qwen2.5vl-Lora1-6_0609/checkpoint-oom-step-301\n",
      "\n",
      "❌ [OOM at step 566] Skipping this batch.\n",
      "    input_ids shape: torch.Size([2, 709])\n",
      "    labels shape: torch.Size([2, 709])\n",
      "💾 Saving checkpoint due to OOM at: ./qwen2.5vl-Lora1-6_0609/checkpoint-oom-step-566\n",
      "\n",
      "❌ [OOM at step 1222] Skipping this batch.\n",
      "    input_ids shape: torch.Size([2, 631])\n",
      "    labels shape: torch.Size([2, 631])\n",
      "💾 Saving checkpoint due to OOM at: ./qwen2.5vl-Lora1-6_0609/checkpoint-oom-step-1222\n",
      "\n",
      "❌ [OOM at step 1223] Skipping this batch.\n",
      "    input_ids shape: torch.Size([2, 629])\n",
      "    labels shape: torch.Size([2, 629])\n",
      "💾 Saving checkpoint due to OOM at: ./qwen2.5vl-Lora1-6_0609/checkpoint-oom-step-1223\n",
      "\n",
      "❌ [OOM at step 1228] Skipping this batch.\n",
      "    input_ids shape: torch.Size([2, 627])\n",
      "    labels shape: torch.Size([2, 627])\n",
      "💾 Saving checkpoint due to OOM at: ./qwen2.5vl-Lora1-6_0609/checkpoint-oom-step-1228\n",
      "\n",
      "❌ [OOM at step 1391] Skipping this batch.\n",
      "    input_ids shape: torch.Size([2, 728])\n",
      "    labels shape: torch.Size([2, 728])\n",
      "💾 Saving checkpoint due to OOM at: ./qwen2.5vl-Lora1-6_0609/checkpoint-oom-step-1391\n",
      "\n",
      "❌ [OOM at step 2620] Skipping this batch.\n",
      "    input_ids shape: torch.Size([2, 660])\n",
      "    labels shape: torch.Size([2, 660])\n",
      "💾 Saving checkpoint due to OOM at: ./qwen2.5vl-Lora1-6_0609/checkpoint-oom-step-2620\n",
      "\n",
      "❌ [OOM at step 3330] Skipping this batch.\n",
      "    input_ids shape: torch.Size([2, 709])\n",
      "    labels shape: torch.Size([2, 709])\n",
      "💾 Saving checkpoint due to OOM at: ./qwen2.5vl-Lora1-6_0609/checkpoint-oom-step-3330\n",
      "\n",
      "❌ [OOM at step 3337] Skipping this batch.\n",
      "    input_ids shape: torch.Size([2, 660])\n",
      "    labels shape: torch.Size([2, 660])\n",
      "💾 Saving checkpoint due to OOM at: ./qwen2.5vl-Lora1-6_0609/checkpoint-oom-step-3337\n",
      "\n",
      "❌ [OOM at step 3376] Skipping this batch.\n",
      "    input_ids shape: torch.Size([2, 747])\n",
      "    labels shape: torch.Size([2, 747])\n",
      "💾 Saving checkpoint due to OOM at: ./qwen2.5vl-Lora1-6_0609/checkpoint-oom-step-3376\n",
      "\n",
      "❌ [OOM at step 3430] Skipping this batch.\n",
      "    input_ids shape: torch.Size([2, 665])\n",
      "    labels shape: torch.Size([2, 665])\n",
      "💾 Saving checkpoint due to OOM at: ./qwen2.5vl-Lora1-6_0609/checkpoint-oom-step-3430\n",
      "\n",
      "❌ [OOM at step 3749] Skipping this batch.\n",
      "    input_ids shape: torch.Size([2, 663])\n",
      "    labels shape: torch.Size([2, 663])\n",
      "💾 Saving checkpoint due to OOM at: ./qwen2.5vl-Lora1-6_0609/checkpoint-oom-step-3749\n",
      "\n",
      "❌ [OOM at step 4263] Skipping this batch.\n",
      "    input_ids shape: torch.Size([2, 728])\n",
      "    labels shape: torch.Size([2, 728])\n",
      "💾 Saving checkpoint due to OOM at: ./qwen2.5vl-Lora1-6_0609/checkpoint-oom-step-4263\n",
      "\n",
      "❌ [OOM at step 4430] Skipping this batch.\n",
      "    input_ids shape: torch.Size([2, 656])\n",
      "    labels shape: torch.Size([2, 656])\n",
      "💾 Saving checkpoint due to OOM at: ./qwen2.5vl-Lora1-6_0609/checkpoint-oom-step-4430\n",
      "\n",
      "❌ [OOM at step 4592] Skipping this batch.\n",
      "    input_ids shape: torch.Size([2, 649])\n",
      "    labels shape: torch.Size([2, 649])\n",
      "💾 Saving checkpoint due to OOM at: ./qwen2.5vl-Lora1-6_0609/checkpoint-oom-step-4592\n",
      "\n",
      "❌ [OOM at step 4597] Skipping this batch.\n",
      "    input_ids shape: torch.Size([2, 626])\n",
      "    labels shape: torch.Size([2, 626])\n",
      "💾 Saving checkpoint due to OOM at: ./qwen2.5vl-Lora1-6_0609/checkpoint-oom-step-4597\n",
      "\n",
      "❌ [OOM at step 4743] Skipping this batch.\n",
      "    input_ids shape: torch.Size([2, 656])\n",
      "    labels shape: torch.Size([2, 656])\n",
      "💾 Saving checkpoint due to OOM at: ./qwen2.5vl-Lora1-6_0609/checkpoint-oom-step-4743\n",
      "\n",
      "❌ [OOM at step 4754] Skipping this batch.\n",
      "    input_ids shape: torch.Size([2, 652])\n",
      "    labels shape: torch.Size([2, 652])\n",
      "💾 Saving checkpoint due to OOM at: ./qwen2.5vl-Lora1-6_0609/checkpoint-oom-step-4754\n",
      "\n",
      "❌ [OOM at step 4755] Skipping this batch.\n",
      "    input_ids shape: torch.Size([2, 630])\n",
      "    labels shape: torch.Size([2, 630])\n",
      "💾 Saving checkpoint due to OOM at: ./qwen2.5vl-Lora1-6_0609/checkpoint-oom-step-4755\n",
      "\n",
      "❌ [OOM at step 4860] Skipping this batch.\n",
      "    input_ids shape: torch.Size([2, 663])\n",
      "    labels shape: torch.Size([2, 663])\n",
      "💾 Saving checkpoint due to OOM at: ./qwen2.5vl-Lora1-6_0609/checkpoint-oom-step-4860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 14:16:53] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5000, training_loss=2.721678611755371, metrics={'train_runtime': 59455.4125, 'train_samples_per_second': 0.673, 'train_steps_per_second': 0.084, 'total_flos': 7.437116562949693e+17, 'train_loss': 2.721678611755371, 'epoch': 10.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cc9f07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4307379722595215, 'eval_BLEU-1': 0.6910088324997434, 'eval_BLEU-4': 0.678180497103904, 'eval_ROUGE-L': 0.7776202860827315, 'eval_KeywordOverlap': 0.9922213705834395, 'eval_ChoiceAccuracy': 1.0, 'eval_runtime': 18.3088, 'eval_samples_per_second': 0.546, 'eval_steps_per_second': 0.546, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5b58901",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./qwen2.5vl-Lora1-6/final_0609_10epoch\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
