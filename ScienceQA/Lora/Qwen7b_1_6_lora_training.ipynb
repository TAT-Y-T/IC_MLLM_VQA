{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a382b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from peft import get_peft_model, PrefixTuningConfig, TaskType\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49cd4aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 筛选后的样本数量: 4349\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "def build_filtered_dataset(dataset_name='derek-thomas/ScienceQA',\n",
    "                           split='train',\n",
    "                           keep_grades='1-6'):\n",
    "    \"\"\"\n",
    "    构建按年级和图像存在性过滤的数据集。\n",
    "\n",
    "    参数:\n",
    "        dataset_name (str): 数据集名称，例如 'derek-thomas/ScienceQA'。\n",
    "        split (str): 数据分割，例如 'train', 'test', 'validation'。\n",
    "        keep_grades (str or None): 筛选的年级段：\"1-6\"、\"7-12\" 或 None 表示不过滤。\n",
    "\n",
    "    返回:\n",
    "        List[Dict]: 筛选后的样本列表。\n",
    "    \"\"\"\n",
    "\n",
    "    def is_grade_allowed(grade_str):\n",
    "        if keep_grades is None:\n",
    "            return True\n",
    "        try:\n",
    "            grade_num = int(grade_str.replace(\"grade\", \"\"))\n",
    "            if keep_grades == \"1-6\":\n",
    "                return 1 <= grade_num <= 6\n",
    "            elif keep_grades == \"7-12\":\n",
    "                return 7 <= grade_num <= 12\n",
    "        except:\n",
    "            return False\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "    data = load_dataset(dataset_name, split=split)\n",
    "    dataset = []\n",
    "\n",
    "    for i, sample in enumerate(data):\n",
    "        try:\n",
    "            if sample.get('question') is None:\n",
    "                continue\n",
    "            \n",
    "            if sample.get(\"image\", None) is None:\n",
    "                continue\n",
    "\n",
    "            if not is_grade_allowed(sample.get(\"grade\", \"\")):\n",
    "                continue\n",
    "\n",
    "            solution = sample.get(\"solution\", \"\")\n",
    "            lecture = sample.get(\"lecture\", \"\")\n",
    "            solution_lecture = f\"{solution}\\n\\n{lecture}\".strip()\n",
    "            \n",
    "            image = sample[\"image\"].convert(\"RGB\")\n",
    "            \n",
    "\n",
    "            # image = np.array(image)\n",
    "            # image = torch.tensor(image).permute(2, 0, 1)  # shape: (C, H, W)\n",
    "            dataset.append({\n",
    "                \"image\": image, \n",
    "                \"question\": sample[\"question\"],\n",
    "                \"choices\": sample[\"choices\"],\n",
    "                \"hint\": sample[\"hint\"],\n",
    "                \"answer\": sample[\"answer\"],\n",
    "                \"solution_lecture\": solution_lecture,\n",
    "                'grade':sample[\"grade\"],\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"跳过第 {i} 个样本，错误：{e}\")\n",
    "            continue\n",
    "    return dataset\n",
    "\n",
    "dataset_train = build_filtered_dataset(split='train', keep_grades='1-6')\n",
    "print(f\"\\n✅ 筛选后的样本数量: {len(dataset_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eebb75bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 筛选后的样本数量: 1481\n"
     ]
    }
   ],
   "source": [
    "dataset_val = build_filtered_dataset(split='validation', keep_grades='1-6')\n",
    "print(f\"\\n✅ 筛选后的样本数量: {len(dataset_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05f98ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which color does this map use to show land that is not covered by water or ice?\n",
      "Choices: ['green and brown', 'blue and white']\n",
      "Hint: This is a map of Earth. The map uses color to show where water, land, and ice are found.\n",
      "Grade: grade3\n",
      "Answer: 0\n",
      "Explanation: Green and brown are used to show land not covered by water or ice.\n",
      "\n",
      "Many maps of Earth use color to show different areas.\n",
      "Green and brown show land that is not covered by water or ice.\n",
      "Blue shows liquid water in oceans, rivers, lakes, and other bodies of water.\n",
      "White shows frozen water. These parts of Earth's surface are covered by ice.\n",
      "Image type: <class 'PIL.Image.Image'>\n"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    "\n",
    "sample_1 = choice(dataset_train)\n",
    "print(f\"Question: {sample_1['question']}\")\n",
    "print(f\"Choices: {sample_1['choices']}\")\n",
    "print(f\"Hint: {sample_1['hint']}\")\n",
    "print(f\"Grade: {sample_1['grade']}\")\n",
    "print(f\"Answer: {sample_1['answer']}\")\n",
    "print(f\"Explanation: {sample_1['solution_lecture']}\")\n",
    "print(f\"Image type: {type(sample_1['image'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c8a5efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "class QwenVLPrefixDataset(Dataset):\n",
    "    def __init__(self, data_list, processor, debug=False):\n",
    "        self.data_list = data_list\n",
    "        self.processor = processor\n",
    "        self.debug = debug\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data_list[idx]\n",
    "        return self.build_training_sample(sample)\n",
    "\n",
    "    def build_training_sample(self, sample):\n",
    "        # 1. 构造答案\n",
    "        if isinstance(sample[\"answer\"], int):\n",
    "            answer_index = sample[\"answer\"]\n",
    "        else:\n",
    "            answer_index = sample[\"choices\"].index(sample[\"answer\"])\n",
    "        answer_letter = chr(65 + answer_index)\n",
    "\n",
    "        # 2. 构建问题内容\n",
    "        question_text = f\"Question: {sample['question']}\\nChoices:\\n\"\n",
    "        for idx, choice in enumerate(sample[\"choices\"]):\n",
    "            question_text += f\"{chr(65 + idx)}. {choice}\\n\"\n",
    "        if sample.get(\"hint\"):\n",
    "            question_text += f\"\\nHint: {sample['hint']}\\n\"\n",
    "        question_text += (\n",
    "            \"\\nHere is a image:\\n\"\n",
    "            \"Please select the correct answer. Then, explain your reasoning in detail. \"\n",
    "            \"Make sure your explanation is at least three sentences long, \"\n",
    "            \"refers to specific data from the image, and shows your step-by-step logic.\"\n",
    "        )\n",
    "\n",
    "        # 3. 构建 label 文本（拼接到 prompt 后）\n",
    "        label_text = f\"\\nAnswer: {answer_letter}\\nExplanation: {sample['solution_lecture']}\"\n",
    "\n",
    "        # 4. 图像处理\n",
    "        image = sample[\"image\"]\n",
    "        if not isinstance(image, Image.Image):\n",
    "            raise ValueError(\"image must be a PIL.Image.Image\")\n",
    "        image = image.convert(\"RGB\").resize((224, 224))\n",
    "\n",
    "        # 5. 构造完整对话 + 图像输入\n",
    "        chat = [\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": question_text},\n",
    "                {\"type\": \"image\", \"image\": image}\n",
    "            ]},\n",
    "            {\"role\": \"assistant\", \"content\": label_text}\n",
    "        ]\n",
    "\n",
    "        # 6. 编码图文输入（注意：一体编码 prompt+label）\n",
    "        text = self.processor.apply_chat_template(chat, tokenize=False, add_generation_prompt=False)\n",
    "        inputs = self.processor(\n",
    "            text=text,\n",
    "            images=image,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=False,\n",
    "            truncation=False\n",
    "        )\n",
    "\n",
    "        # 7. 构造 labels —— 用 input_ids 克隆，并 mask 掉前面的 prompt\n",
    "        input_ids = inputs[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = inputs[\"attention_mask\"].squeeze(0)\n",
    "\n",
    "        # 找到 label 的起始位置：用 processor 再只 encode user 部分计算长度\n",
    "        user_text_only = self.processor.apply_chat_template(chat[:1], tokenize=False, add_generation_prompt=False)\n",
    "        user_input_ids = self.processor.tokenizer(user_text_only, return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"][0]\n",
    "        user_len = user_input_ids.shape[-1]\n",
    "\n",
    "        labels = input_ids.clone()\n",
    "        labels[:user_len] = -100  # mask prompt 部分\n",
    "\n",
    "        result = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels,\n",
    "            \"pixel_values\": inputs[\"pixel_values\"].squeeze(0),\n",
    "        }\n",
    "\n",
    "        if \"image_grid_thw\" in inputs:\n",
    "            result[\"image_grid_thw\"] = inputs[\"image_grid_thw\"].squeeze(0)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"[DEBUG] input_ids.shape: {input_ids.shape}\")\n",
    "            print(f\"[DEBUG] labels.shape: {labels.shape}\")\n",
    "\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5519615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\")\n",
    "train_dataset = QwenVLPrefixDataset(dataset_train, processor, debug=False)\n",
    "dataloader = DataLoader(dataset_train, batch_size=6, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f8434da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def qwen_vl_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collate 函数，用于 QwenVL 多模态模型训练。\n",
    "    自动对 input_ids / labels 进行 padding，\n",
    "    pixel_values 和 image_grid_thw 直接 stack（假设 shape 一致）。\n",
    "    \"\"\"\n",
    "    def pad_tensor_list(tensor_list, pad_value=0):\n",
    "        return pad_sequence(tensor_list, batch_first=True, padding_value=pad_value)\n",
    "\n",
    "    input_ids = [item[\"input_ids\"] for item in batch]\n",
    "    attention_mask = [item[\"attention_mask\"] for item in batch]\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "\n",
    "    # 部分模型 forward 需要 attention_mask，尽管有些模型不强依赖，也建议保留\n",
    "    input_ids = pad_tensor_list(input_ids, pad_value=0)\n",
    "    attention_mask = pad_tensor_list(attention_mask, pad_value=0)\n",
    "    labels = pad_tensor_list(labels, pad_value=-100)  # 避免 loss 对 pad token 计算\n",
    "\n",
    "    # 多模态部分\n",
    "    pixel_values = torch.stack([item[\"pixel_values\"] for item in batch])\n",
    "    \n",
    "    # 可选：容错处理 image_grid_thw（有些模型可能没有）\n",
    "    if \"image_grid_thw\" in batch[0]:\n",
    "        image_grid_thw = torch.stack([item[\"image_grid_thw\"] for item in batch])\n",
    "    else:\n",
    "        image_grid_thw = None\n",
    "\n",
    "    # 构造返回字典\n",
    "    result = {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels,\n",
    "        \"pixel_values\": pixel_values,\n",
    "    }\n",
    "    # print(f\"input_ids shape: {input_ids.shape}, attention_mask shape: {attention_mask.shape}, labels shape: {labels.shape}, pixel_values shape: {pixel_values.shape}\")\n",
    "    if image_grid_thw is not None:\n",
    "        result[\"image_grid_thw\"] = image_grid_thw\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79562971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== 第一个 batch 的第一个样本 ====\n",
      "input_ids shape: torch.Size([270])\n",
      "attention_mask shape: torch.Size([270])\n",
      "labels shape: torch.Size([270])\n",
      "pixel_values shape: torch.Size([256, 1176])\n",
      "image_grid_thw shape: torch.Size([3])\n",
      "\n",
      "--- 解码后的 input_ids ---\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Question: Which of these states is farthest north?\n",
      "Choices:\n",
      "A. West Virginia\n",
      "B. Louisiana\n",
      "C. Arizona\n",
      "D. Oklahoma\n",
      "\n",
      "Here is a image:\n",
      "Please select the correct answer. Then, explain your reasoning in detail. Make sure your explanation is at least three sentences long, refers to specific data from the image, and shows your step-by-step logic.\n",
      "assistant\n",
      "\n",
      "Answer: A\n",
      "Explanation: To find the answer, look at the compass rose. Look at which way the north arrow is pointing. West Virginia is farthest north.\n",
      "\n",
      "Maps have four cardinal directions, or main directions. Those directions are north, south, east, and west.\n",
      "A compass rose is a set of arrows that point to the cardinal directions. A compass rose usually shows only the first letter of each cardinal direction.\n",
      "The north arrow points to the North Pole. On most maps, north is at the top of the map.\n",
      "\n",
      "\n",
      "--- 解码后的 labels ---\n",
      "\n",
      "assistant\n",
      "\n",
      "Answer: A\n",
      "Explanation: To find the answer, look at the compass rose. Look at which way the north arrow is pointing. West Virginia is farthest north.\n",
      "\n",
      "Maps have four cardinal directions, or main directions. Those directions are north, south, east, and west.\n",
      "A compass rose is a set of arrows that point to the cardinal directions. A compass rose usually shows only the first letter of each cardinal direction.\n",
      "The north arrow points to the North Pole. On most maps, north is at the top of the map.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 正确使用 collate_fn\n",
    "dataloader = DataLoader(train_dataset, batch_size=1, shuffle=False, collate_fn=qwen_vl_collate_fn)\n",
    "\n",
    "# 获取第一个 batch\n",
    "first_batch = next(iter(dataloader))\n",
    "\n",
    "# 查看第一个样本的结构\n",
    "n = 0\n",
    "print(\"==== 第一个 batch 的第一个样本 ====\")\n",
    "print(f\"input_ids shape: {first_batch['input_ids'][n].shape}\")\n",
    "print(f\"attention_mask shape: {first_batch['attention_mask'][0].shape}\")\n",
    "print(f\"labels shape: {first_batch['labels'][n].shape}\")\n",
    "print(f\"pixel_values shape: {first_batch['pixel_values'][n].shape}\")\n",
    "print(f\"image_grid_thw shape: {first_batch['image_grid_thw'][n].shape}\")\n",
    "\n",
    "# 可选：查看文本内容（需要 tokenizer）\n",
    "tokenizer = processor.tokenizer\n",
    "decoded_input = tokenizer.decode(first_batch['input_ids'][n], skip_special_tokens=True)\n",
    "decoded_label = tokenizer.decode(\n",
    "    [id for id in first_batch['labels'][n].tolist() if id != -100],\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(\"\\n--- 解码后的 input_ids ---\")\n",
    "print(decoded_input)\n",
    "\n",
    "print(\"\\n--- 解码后的 labels ---\")\n",
    "print(decoded_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fbbc6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653993701f7944fbb9cad9fe2f37e8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-7B-Instruct\", device_map=\"auto\", torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c7ad94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,523,136 || all params: 8,294,689,792 || trainable%: 0.0304\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,  # 对于 Qwen 这类生成模型，使用 CAUSAL_LM\n",
    "    inference_mode=False,          # 表示用于训练，不是推理\n",
    "    r=8,                           # LoRA 秩，越大可训练参数越多（常见：4, 8, 16）\n",
    "    lora_alpha=32,                 # 缩放因子，通常与 r 同阶或更大\n",
    "    lora_dropout=0.1,              # dropout，防止过拟合\n",
    "    target_modules=[\"q_proj\", \"v_proj\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "796f8352",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):  # 屏蔽 num_items_in_batch\n",
    "        if \"num_items_in_batch\" in kwargs:\n",
    "            kwargs.pop(\"num_items_in_batch\")\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "14060ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge import Rouge\n",
    "\n",
    "def parse_output(output: str):\n",
    "    \"\"\"\n",
    "    提取选择题答案和解释文本，容错支持 Answer: A, A., A: 等。\n",
    "    返回 answer: int (0~3 对应 A-D), explanation: str\n",
    "    \"\"\"\n",
    "    output = output.strip()\n",
    "    answer_match = re.search(r\"(?i)\\banswer\\s*[:\\-]?\\s*([A-D])\\b\", output)\n",
    "    if not answer_match:\n",
    "        answer_match = re.search(r\"\\b([A-D])[\\.\\:\\-]\", output)\n",
    "\n",
    "    if answer_match:\n",
    "        choice_char = answer_match.group(1).upper()\n",
    "        answer = ord(choice_char) - ord(\"A\")\n",
    "    else:\n",
    "        answer = -1\n",
    "\n",
    "    explanation = \"\"\n",
    "    if answer_match:\n",
    "        idx = output.find(answer_match.group(0))\n",
    "        if idx != -1:\n",
    "            explanation = output[idx + len(answer_match.group(0)):].strip()\n",
    "\n",
    "    return answer, explanation\n",
    "\n",
    "def keyword_overlap(pred, ref):\n",
    "    pred_keywords = set(pred.lower().split())\n",
    "    ref_keywords = set(ref.lower().split())\n",
    "    if not ref_keywords:\n",
    "        return 0.0\n",
    "    return len(pred_keywords & ref_keywords) / len(ref_keywords)\n",
    "\n",
    "def compute_metrics(eval_preds, tokenizer):\n",
    "    predictions = eval_preds.predictions\n",
    "    label_ids = eval_preds.label_ids\n",
    "\n",
    "    # 如果 predictions 是 tuple（例如包含 logits），取第一个作为 token ids\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "\n",
    "    # 如果是 logits（形如 [batch, seq_len, vocab_size]），则 argmax 得到 token ids\n",
    "    if predictions.ndim == 3:\n",
    "        predictions = predictions.argmax(-1)\n",
    "\n",
    "    decoded_preds = []\n",
    "    decoded_labels = []\n",
    "\n",
    "    for pred_ids, label in zip(predictions, label_ids):\n",
    "        label = [id for id in label if id != -100]\n",
    "        decoded_pred = tokenizer.decode(pred_ids, skip_special_tokens=True)\n",
    "        decoded_label = tokenizer.decode(label, skip_special_tokens=True)\n",
    "\n",
    "        decoded_preds.append(decoded_pred.strip())\n",
    "        decoded_labels.append(decoded_label.strip())\n",
    "\n",
    "    # 打印第一个样本的预测和标签\n",
    "    print(\"\\n==== 示例输出 ====\")\n",
    "    print(\"预测：\", decoded_preds[0])\n",
    "    print(\"标签：\", decoded_labels[0])\n",
    "\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    bleu1_scores = []\n",
    "    bleu4_scores = []\n",
    "    rouge_l_scores = []\n",
    "    keyword_overlaps = []\n",
    "    choice_correct = []\n",
    "\n",
    "    rouge = Rouge()\n",
    "\n",
    "    for pred, label in zip(decoded_preds, decoded_labels):\n",
    "        reference = label.split()\n",
    "        candidate = pred.split()\n",
    "\n",
    "        # BLEU-1 和 BLEU-4\n",
    "        bleu1 = sentence_bleu([reference], candidate, weights=(1, 0, 0, 0), smoothing_function=smoothie)\n",
    "        bleu4 = sentence_bleu([reference], candidate, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie)\n",
    "        bleu1_scores.append(bleu1)\n",
    "        bleu4_scores.append(bleu4)\n",
    "\n",
    "        # ROUGE-L\n",
    "        try:\n",
    "            rouge_l = rouge.get_scores(pred, label)[0]['rouge-l']['f']\n",
    "        except ValueError:\n",
    "            rouge_l = 0.0\n",
    "        rouge_l_scores.append(rouge_l)\n",
    "\n",
    "        # Keyword overlap\n",
    "        keyword_acc = keyword_overlap(pred, label)\n",
    "        keyword_overlaps.append(keyword_acc)\n",
    "\n",
    "        # Choice accuracy\n",
    "        pred_choice, _ = parse_output(pred)\n",
    "        label_choice, _ = parse_output(label)\n",
    "        is_correct = (pred_choice == label_choice) and (pred_choice != -1)\n",
    "        choice_correct.append(int(is_correct))\n",
    "\n",
    "    return {\n",
    "        \"BLEU-1\": np.mean(bleu1_scores),\n",
    "        \"BLEU-4\": np.mean(bleu4_scores),\n",
    "        \"ROUGE-L\": np.mean(rouge_l_scores),\n",
    "        \"KeywordOverlap\": np.mean(keyword_overlaps),\n",
    "        \"ChoiceAccuracy\": np.mean(choice_correct),\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f3586bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\")\n",
    "small_train_dataset=dataset_train[:100] \n",
    "small_val_dataset=dataset_val[:10]\n",
    "train_dataset = QwenVLPrefixDataset(small_train_dataset, processor, debug=False)\n",
    "val_dataset = QwenVLPrefixDataset(small_val_dataset, processor, debug=False)    \n",
    "dataloader = DataLoader(train_dataset, batch_size=6, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "804580d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "[codecarbon ERROR @ 14:01:45] Error: Another instance of codecarbon is probably running as we find `/tmp/.codecarbon.lock`. Turn off the other instance to be able to run this one or use `allow_multiple_runs` or delete the file. Exiting.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qwen2.5vl-Lora1-6\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=1, \n",
    "    dataloader_num_workers=0,\n",
    "    eval_accumulation_steps=1,\n",
    "    learning_rate=5e-4,\n",
    "    num_train_epochs=50,\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    bf16=True,  # 如果使用的是支持 bfloat16 的 GPU，可改为 bf16=True\n",
    "    gradient_accumulation_steps=4,\n",
    "    remove_unused_columns=False\n",
    "\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=qwen_vl_collate_fn,\n",
    "    compute_metrics=lambda p: compute_metrics(p, tokenizer=processor.tokenizer)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a21c2d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 14:01:47] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 1:46:47, Epoch 46/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.868400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.500500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.517600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.547400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.656500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.589600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.632400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.414200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.596800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.309000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.629100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.528900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.523000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.699000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.504300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.677400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.658000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.662100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.551200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.762200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.356000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.650500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.749400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.667100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.703100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.668300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.355900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.600600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.531200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.664600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2.372900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.565900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.555200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.345300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2.579600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.581600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.519600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.554600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>2.453600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.643800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.585000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.241500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.628400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.488300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.627100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.597700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.576000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.357700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.650500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.577500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.355400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.714400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.395100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.734200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.418500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.420900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.351200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 15:48:43] Another instance of codecarbon is already running. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=600, training_loss=2.5466853205362954, metrics={'train_runtime': 6416.6487, 'train_samples_per_second': 0.779, 'train_steps_per_second': 0.094, 'total_flos': 8.555455835384218e+16, 'train_loss': 2.5466853205362954, 'epoch': 46.16})"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9cc9f07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== 示例输出 ====\n",
      "预测： nock钗 in text a辱 andأسب\n",
      "\n",
      "\n",
      "what one has habitat is the its for digging feeding:A squidos fishfishaggerons the thebrates and including, and other.InputStream feedersers their prey on the bottom of the and ponds, and oceans ocean answerequalเทคโน is also the underside of the body. is downward. mouth is adapted for bottom esp.exThe: Theurgeon with---Ṣ\n",
      "assistant\n",
      "\n",
      "Answer: A\n",
      "Explanation: Look at the picture of the sturgeon.\n",
      "The sturgeon has mouth is located on the underside of its head and points downward. Its mouth is adapted for bottom feeding.\n",
      " The sturgeon uses its mouth to dig and at in the bottom at the bottom of rivers, lakes, and the ocean.\n",
      "Now look at each animal. Figure out which animal has a similar adaptation.\n",
      "The armored catfish's mouth points adapted on the underside of its head and points downward. Its mouth is adapted for bottom feeding.\n",
      "The discus's mouth is not adapted on the underside of its head. It mouth is not adapted for bottom feeding.\n",
      "\n",
      "An adaptation is an inherited trait that helps an organism survive or reproduce. Adaptations can include both body parts and behaviors.\n",
      "The shape of an animal's mouth is one example of an adaptation. Animals' mouths can be adapted in different ways. For example, a large mouth with sharp teeth might help pick animal break through meat. A small, thin mouth might help an animal reach insects that live in holes. that eat similar food often have adapted mouths.\n",
      "标签： assistant\n",
      "\n",
      "Answer: B\n",
      "Explanation: Look at the picture of the sturgeon.\n",
      "The sturgeon's mouth is located on the underside of its head and points downward. Its mouth is adapted for bottom feeding. The sturgeon uses its mouth to find food hidden in the sediment at the bottom of rivers, lakes, and the ocean.\n",
      "Now look at each animal. Figure out which animal has a similar adaptation.\n",
      "The armored catfish's mouth is located on the underside of its head and points downward. Its mouth is adapted for bottom feeding.\n",
      "The discus's mouth is not located on the underside of its head. Its mouth is not adapted for bottom feeding.\n",
      "\n",
      "An adaptation is an inherited trait that helps an organism survive or reproduce. Adaptations can include both body parts and behaviors.\n",
      "The shape of an animal's mouth is one example of an adaptation. Animals' mouths can be adapted in different ways. For example, a large mouth with sharp teeth might help an animal tear through meat. A long, thin mouth might help an animal catch insects that live in holes. Animals that eat similar food often have similar mouths.\n",
      "{'eval_loss': 2.709097385406494, 'eval_BLEU-1': 0.7422953266552378, 'eval_BLEU-4': 0.672091535667492, 'eval_ROUGE-L': 0.8223715978383073, 'eval_KeywordOverlap': 0.9399455527783825, 'eval_ChoiceAccuracy': 0.8, 'eval_runtime': 17.8956, 'eval_samples_per_second': 0.559, 'eval_steps_per_second': 0.559, 'epoch': 46.16}\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c5b58901",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./qwen2.5vl-Lora1-6/final\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
